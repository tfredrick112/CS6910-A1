{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS6910 Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J2rW7irVISu"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRxhb9DQWWMl",
        "outputId": "424bd374-2f2c-4cd2-fae7-8fa44f0a30fc"
      },
      "source": [
        "! pip install wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/17/b1e27f77c3d47f6915a774ecf632e3f5a7d49d9fa3991547729e7f19bedd/wandb-0.10.21-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 13.8MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.9MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.0.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=b3db0c60cb64c3ae585690e653dd9da4735ad3aa47f4d25b05ccc759ea86ba07\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=4a69dc15dc2d24d932cbd3a5c13eceab1916b27c9ef596270fda20d767fee70c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: subprocess32, configparser, sentry-sdk, shortuuid, pathtools, smmap, gitdb, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7jmBIjlUoWo"
      },
      "source": [
        "import warnings\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.datasets import fashion_mnist\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "import wandb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "WjoerVOKdqsi",
        "outputId": "1e29f418-a563-491c-e7de-bf9a690f67e8"
      },
      "source": [
        "wandb.init(project=\"dl_assignment1\", entity=\"ee17b154tony\", name=\"assignment_1\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdjbagadthey\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.21<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">assignment_1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/djbagadthey/dl_assignment1\" target=\"_blank\">https://wandb.ai/djbagadthey/dl_assignment1</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/djbagadthey/dl_assignment1/runs/2l6brycp\" target=\"_blank\">https://wandb.ai/djbagadthey/dl_assignment1/runs/2l6brycp</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210304_040055-2l6brycp</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa5f8d6e750>"
            ],
            "text/html": [
              "<h1>Run(2l6brycp)</h1><iframe src=\"https://wandb.ai/djbagadthey/dl_assignment1/runs/2l6brycp\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjWCKvIkVp5r"
      },
      "source": [
        "#### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bixsCKMnVmmY",
        "outputId": "725f90ac-6805-4762-eafa-e91f3239a5c9"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dINMYRThaEBS"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFQWcmriZHFM",
        "outputId": "3305d9e1-61b8-4406-ec50-6c1ee4d05ed5"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  41, 188, 103,\n",
              "         54,  48,  43,  87, 168, 133,  16,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,  49, 136, 219, 216, 228, 236,\n",
              "        255, 255, 255, 255, 217, 215, 254, 231, 160,  45,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  14, 176, 222, 224, 212, 203, 198, 196,\n",
              "        200, 215, 204, 202, 201, 201, 201, 209, 218, 224, 164,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 188, 219, 200, 198, 202, 198, 199, 199,\n",
              "        201, 196, 198, 198, 200, 200, 200, 200, 201, 200, 225,  41,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  51, 219, 199, 203, 203, 212, 238, 248, 250,\n",
              "        245, 249, 246, 247, 252, 248, 235, 207, 203, 203, 222, 140,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 116, 226, 206, 204, 207, 204, 101,  75,  47,\n",
              "         73,  48,  50,  45,  51,  63, 113, 222, 202, 206, 220, 224,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 200, 222, 209, 203, 215, 200,   0,  70,  98,\n",
              "          0, 103,  59,  68,  71,  49,   0, 219, 206, 214, 210, 250,  38,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 247, 218, 212, 210, 215, 214,   0, 254, 243,\n",
              "        139, 255, 174, 251, 255, 205,   0, 215, 217, 214, 208, 220,  95,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,  45, 226, 214, 214, 215, 224, 205,   0,  42,  35,\n",
              "         60,  16,  17,  12,  13,  70,   0, 189, 216, 212, 206, 212, 156,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 164, 235, 214, 211, 220, 216, 201,  52,  71,  89,\n",
              "         94,  83,  78,  70,  76,  92,  87, 206, 207, 222, 213, 219, 208,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 106, 187, 223, 237, 248, 211, 198, 252, 250, 248,\n",
              "        245, 248, 252, 253, 250, 252, 239, 201, 212, 225, 215, 193, 113,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  17,  54, 159, 222, 193, 208, 192, 197,\n",
              "        200, 200, 200, 200, 201, 203, 195, 210, 165,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  47, 225, 192, 214, 203, 206,\n",
              "        204, 204, 205, 206, 204, 212, 197, 218, 107,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   1,   6,   0,  46, 212, 195, 212, 202, 206,\n",
              "        205, 204, 205, 206, 204, 212, 200, 218,  91,   0,   3,   1,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,  11, 197, 199, 205, 202, 205,\n",
              "        206, 204, 205, 207, 204, 205, 205, 218,  77,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   3,   0,   2, 191, 198, 201, 205, 206,\n",
              "        205, 205, 206, 209, 206, 199, 209, 219,  74,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 188, 197, 200, 207, 207,\n",
              "        204, 207, 207, 210, 208, 198, 207, 221,  72,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 215, 198, 203, 206, 208,\n",
              "        205, 207, 207, 210, 208, 200, 202, 222,  75,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 212, 198, 209, 206, 209,\n",
              "        206, 208, 207, 211, 206, 205, 198, 221,  80,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 201, 205, 208, 207,\n",
              "        205, 211, 205, 210, 210, 209, 195, 221,  96,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 202, 201, 205, 209, 207,\n",
              "        205, 213, 206, 210, 209, 210, 194, 217, 105,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 204, 205, 208, 207,\n",
              "        205, 215, 207, 210, 208, 211, 193, 213, 115,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 204, 207, 207, 208, 206,\n",
              "        206, 215, 210, 210, 207, 212, 195, 210, 118,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 208, 208, 208, 204,\n",
              "        207, 212, 212, 210, 207, 211, 196, 207, 121,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 210, 207, 208, 206,\n",
              "        209, 213, 212, 211, 207, 210, 197, 207, 124,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 172, 210, 203, 201, 199,\n",
              "        204, 207, 205, 204, 201, 205, 197, 206, 127,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 188, 221, 214, 234, 236,\n",
              "        238, 244, 244, 244, 240, 243, 214, 224, 162,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 139, 146, 130, 135, 135,\n",
              "        137, 125, 124, 125, 121, 119, 114, 130,  76,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQRZa7dDVpgi",
        "outputId": "be1884ce-1abf-4565-e243-8d4c5751879a"
      },
      "source": [
        "# Number of training examples\r\n",
        "M = X_train.shape[0]\r\n",
        "\r\n",
        "# Number of test examples\r\n",
        "Mtest = X_test.shape[0]\r\n",
        "\r\n",
        "# Number of features in the dataset\r\n",
        "num_features = X_train.shape[1] * X_train.shape[2]\r\n",
        "\r\n",
        "# Number of classes\r\n",
        "num_classes = len(np.unique(y_train))\r\n",
        "\r\n",
        "# One hot encoding for class labels\r\n",
        "y_train_one_hot = np.zeros((10, M))\r\n",
        "y_train_one_hot[y_train, np.array(list(range(M)))] = 1\r\n",
        "y_train_one_hot = y_train_one_hot.T\r\n",
        "\r\n",
        "y_test_one_hot = np.zeros((10, Mtest))\r\n",
        "y_test_one_hot[y_test, np.array(list(range(Mtest)))] = 1\r\n",
        "y_test_one_hot = y_test_one_hot.T\r\n",
        "\r\n",
        "print(\"Number of images in the training set =\", M)\r\n",
        "print(\"Number of images in the test set =\", Mtest)\r\n",
        "print(\"Number of classes =\", num_classes)\r\n",
        "print(\"Number of features per example =\", num_features)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the training set = 60000\n",
            "Number of images in the test set = 10000\n",
            "Number of classes = 10\n",
            "Number of features per example = 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYR7T7ZnYmBp"
      },
      "source": [
        "### Logging Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTcyI8f8V8kH"
      },
      "source": [
        "# Store the index of first occurrence of each class\r\n",
        "example_indices = [list(y_train).index(i) for i in range(num_classes)]\r\n",
        "\r\n",
        "# example_images is a list containing one sample image per class, example_captions stores the corresponsing captions\r\n",
        "example_images = []\r\n",
        "example_captions = []\r\n",
        "for index in example_indices:\r\n",
        "    example_images.append(X_train[index])\r\n",
        "    example_captions.append(class_names[y_train[index]])\r\n",
        "\r\n",
        "# Log one sample image of each class to wandb\r\n",
        "wandb.log({\"Sample Image from each class\": [wandb.Image(image, caption=caption) for image, caption in zip(example_images, example_captions)]})"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsNV-0oNwvTv"
      },
      "source": [
        "### Number of neurons in the input and output layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMu1LWJAam8g"
      },
      "source": [
        "input_nodes = num_features\r\n",
        "output_nodes = num_classes"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xczQae_C0Htr"
      },
      "source": [
        "### Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNl7CMOD0HNJ"
      },
      "source": [
        "def tanh(x):\r\n",
        "    return np.tanh(x)\r\n",
        "\r\n",
        "def tanh_derivative(x):\r\n",
        "    # x is the tanh value\r\n",
        "    return (1 - (np.tanh(x)**2))\r\n",
        "\r\n",
        "def sigmoid(x):\r\n",
        "    return 1.0/(1+ np.exp(-x))\r\n",
        "\r\n",
        "def sigmoid_derivative(x):\r\n",
        "    return sigmoid(x) * (1.0 - sigmoid(x))\r\n",
        "\r\n",
        "def softmax(x):\r\n",
        "    \"\"\"Compute the softmax of vector x in a numerically stable way.\"\"\"\r\n",
        "    shiftx = x - np.max(x)\r\n",
        "    exps = np.exp(shiftx)\r\n",
        "    return exps / np.sum(exps)\r\n",
        "\r\n",
        "def ReLU(x):\r\n",
        "    return x * (x > 0)\r\n",
        "\r\n",
        "def ReLU_derivative(x):\r\n",
        "    return x>0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psuJOVx316Xo"
      },
      "source": [
        "### Loss Function and its derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mGBJouA15ni"
      },
      "source": [
        "def crossentropyloss(y, y_hat):\r\n",
        "    \"\"\"Categorical cross-entropy loss\"\"\"\r\n",
        "    return -np.sum(y.reshape(y_hat.shape) * np.log(y_hat))\r\n",
        "\r\n",
        "def crossentropyloss_derivative(y, y_hat):\r\n",
        "    \"\"\"Derivative of the cross entropy loss\"\"\"\r\n",
        "    return -np.divide(y, y_hat)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMulpov3736b"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hRl4yBc7sX7"
      },
      "source": [
        "def initialize_parameters(layer_dims, initialization_option=\"random\"):\r\n",
        "    \"\"\"\r\n",
        "    This function is used to initialize the weights and biases of the network, using either 'random'\r\n",
        "    or 'xavier' or 'normal' initialization depending on the parameter: initialization_option\r\n",
        "\r\n",
        "    layer_dims is a list containing layer sizes (includes input and output layer).\r\n",
        "    \"\"\"\r\n",
        "    np.random.seed(42)\r\n",
        "    parameters = {} # Initialize parameter dictionary\r\n",
        "    \r\n",
        "    for i in range(1, len(layer_dims)):\r\n",
        "        if initialization_option==\"random\":\r\n",
        "          W = np.random.rand(layer_dims[i], layer_dims[i-1]) # uniform distribution\r\n",
        "\r\n",
        "        elif initialization_option == \"normal\":\r\n",
        "          W = np.random.randn(layer_dims[i], layer_dims[i-1]) # normal distribution\r\n",
        "\r\n",
        "        elif initialization_option==\"xavier\":\r\n",
        "          W = np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(2/(layer_dims[i]+layer_dims[i-1])) # glorot normal distribution / Xavier\r\n",
        "\r\n",
        "        # Initialize the biases with zeros\r\n",
        "        b = np.zeros((layer_dims[i], 1))\r\n",
        "        parameters[\"W\"+str(i)] = W\r\n",
        "        parameters[\"b\"+str(i)] = b\r\n",
        "    \r\n",
        "    return parameters"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcwQYdkJJbV-"
      },
      "source": [
        "### Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rISPK7RsJhC9"
      },
      "source": [
        "def forward_propagation(X, parameters, batch_size=1, act_function=\"sigmoid\"):\r\n",
        "    \"\"\"\r\n",
        "    Given inputs X, it performs forward propagation and returns the output.\r\n",
        "    \"\"\"\r\n",
        "    L = len(layer_dims) # total number of layers\r\n",
        "    H = [None]*L # activations\r\n",
        "    A = [None]*L # pre-activations\r\n",
        "    H[0] = X.reshape((num_features, batch_size))\r\n",
        "    \r\n",
        "    for l in range(1, L):\r\n",
        "        W = parameters[\"W\"+str(l)]\r\n",
        "        b = parameters[\"b\"+str(l)]\r\n",
        "        A[l] = np.dot(W, H[l-1]) + b # Computes the pre-activation\r\n",
        "        if l == L-1:\r\n",
        "            H[l] = softmax(A[l]) # activation function for output layers\r\n",
        "        else:\r\n",
        "            if act_function==\"sigmoid\":\r\n",
        "                H[l] = sigmoid(A[l])\r\n",
        "            elif act_function==\"tanh\":\r\n",
        "                H[l] = tanh(A[l])\r\n",
        "            elif act_function==\"relu\":\r\n",
        "                H[l] = ReLU(A[l])\r\n",
        "            \r\n",
        "    output = H[L-1]\r\n",
        "            \r\n",
        "    return output, H, A"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMt-s-8PNwS1"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5_DA--ytSIL"
      },
      "source": [
        "def backprop(y_hat, y, H, A, parameters, act_function=\"sigmoid\"):\r\n",
        "    gradients = {}\r\n",
        "\r\n",
        "    L = len(parameters)//2\r\n",
        "    \r\n",
        "    # Derivative of the loss function wrt A[L] \r\n",
        "    gradients[\"dA\"+str(L)] = y_hat - y.reshape(-1, 1)   \r\n",
        "\r\n",
        "    for l in range(L, 0, -1):\r\n",
        "        gradients[\"dW\"+str(l)] = np.dot(gradients[\"dA\"+str(l)], H[l-1].T)\r\n",
        "        gradients[\"db\"+str(l)] = gradients[\"dA\"+str(l)]\r\n",
        "        gradients[\"dH\"+str(l-1)] = np.dot(parameters[\"W\"+str(l)].T, gradients[\"dA\"+str(l)])\r\n",
        "\r\n",
        "        if l > 1:\r\n",
        "            if act_function==\"sigmoid\":\r\n",
        "                gradients[\"dA\"+str(l-1)] = np.multiply(gradients[\"dH\"+str(l-1)], sigmoid_derivative(A[l-1]))\r\n",
        "            elif act_function==\"tanh\":\r\n",
        "                gradients[\"dA\"+str(l-1)] = np.multiply(gradients[\"dH\"+str(l-1)], tanh_derivative(A[l-1]))\r\n",
        "            elif act_function==\"relu\":\r\n",
        "                gradients[\"dA\"+str(l-1)] = np.multiply(gradients[\"dH\"+str(l-1)], ReLU_derivative(A[l-1]))\r\n",
        "        \r\n",
        "    return gradients"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWgzQqPy1R9q"
      },
      "source": [
        "### Updating parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsU0RrF6zlFX"
      },
      "source": [
        "def update_parameters_sgd(parameters, grads, learning_rate):\r\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\r\n",
        "\r\n",
        "    for l in range(1, L + 1):\r\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)]\r\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)]\r\n",
        "\r\n",
        "    return parameters\r\n",
        "\r\n",
        "def update_parameters_momentum(parameters, grads, learning_rate, beta, previous_updates):\r\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\r\n",
        "\r\n",
        "    for l in range(1, L + 1):\r\n",
        "        previous_updates[\"W\"+str(l)] = beta*previous_updates[\"W\"+str(l)] + (1-beta)*grads[\"dW\" + str(l)]\r\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*previous_updates[\"W\"+str(l)]\r\n",
        "        \r\n",
        "        previous_updates[\"b\"+str(l)] = beta*previous_updates[\"b\"+str(l)] + (1-beta)*grads[\"db\" + str(l)]\r\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate*previous_updates[\"b\"+str(l)]\r\n",
        "\r\n",
        "    return parameters, previous_updates"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PKa0Q1e1v_G"
      },
      "source": [
        "def NN_model(X_train, y_train, X_test, y_test, layer_dims, learning_rate=0.001, beta=0.9,max_epochs=500):\r\n",
        "    parameters = initialize_parameters(layer_dims,\"xavier\")\r\n",
        "    \r\n",
        "    epoch_cost = [] # average training cost at the end of every epoch\r\n",
        "    \r\n",
        "    prev_epoch_cost = 100000 # some large initial value\r\n",
        "    curr_epoch_cost = 0\r\n",
        "    \r\n",
        "    validation_epoch_cost = [] # average validation cost at the end of every epoch\r\n",
        "    \r\n",
        "    count=1 # keeps track of the number of epochs\r\n",
        "    # An epoch is one complete pass through the training data\r\n",
        "\r\n",
        "    while abs(prev_epoch_cost-curr_epoch_cost) > 1e-7 and count<=max_epochs:\r\n",
        "        costs = []# training costs\r\n",
        "        val_costs = []# validation costs\r\n",
        "        count+=1# increment the number of epochs\r\n",
        "        for i in range(len(X_train)):\r\n",
        "            output, H, A = forward_propagation(X_train[i], parameters, act_function=\"sigmoid\")\r\n",
        "            cost = crossentropyloss(y_train[i], output)\r\n",
        "            gradients = backprop(output, y_train[i], H, A, parameters, act_function=\"sigmoid\")\r\n",
        "\r\n",
        "            # print(gradients)\r\n",
        "\r\n",
        "            parameters = update_parameters_sgd(parameters, gradients, learning_rate)\r\n",
        "\r\n",
        "            # parameters, previous_updates = update_parameters_momentum(\r\n",
        "            #                                                     parameters, gradients, learning_rate, beta,\r\n",
        "            #                                                     previous_updates)\r\n",
        "            costs.append(cost)\r\n",
        "            \r\n",
        "        # vaidation part (these examples do not contribute to parameter update)\r\n",
        "        # therefore, the 'model' has still not seen these examples.\r\n",
        "        for j in range(len(X_test)):\r\n",
        "            out, _, _ = forward_propagation(X_test[j], parameters)\r\n",
        "            cost = crossentropyloss(y_test[j], out)\r\n",
        "            val_costs.append(cost)\r\n",
        "            \r\n",
        "        # average training loss for one epoch\r\n",
        "        curr_epoch_cost = sum(costs)/len(X_train)\r\n",
        "        if len(epoch_cost) >= 1:\r\n",
        "            prev_epoch_cost = epoch_cost[-1]\r\n",
        "        epoch_cost.append(curr_epoch_cost)\r\n",
        "        print(\"Current_epoch cost =\", curr_epoch_cost)\r\n",
        "        # average validation loss for one epoch\r\n",
        "        validation_epoch_cost.append(sum(val_costs)/len(X_test))\r\n",
        "        \r\n",
        "    plot_cost_curve(epoch_cost, validation_epoch_cost)\r\n",
        "    return parameters, epoch_cost"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt_1_w8yX9RU"
      },
      "source": [
        "#### Plot Cost Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KedRZbF5X9x6"
      },
      "source": [
        "def plot_cost_curve(train_costs, val_costs):\r\n",
        "    plt.plot(list(range(len(train_costs))), train_costs, 'r', label=\"Training loss\")\r\n",
        "    plt.plot(list(range(len(val_costs))), val_costs, 'lime', label=\"Validation loss\")\r\n",
        "    plt.title(\"Training Loss vs Number of Epochs\", size=18)\r\n",
        "    plt.xlabel(\"Number of epochs\", size=14)\r\n",
        "    plt.ylabel(\"Loss\", size=14)\r\n",
        "    plt.grid()\r\n",
        "    plt.legend()\r\n",
        "    plt.show()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvUhP11LHJZB"
      },
      "source": [
        "### Predictions and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRX37lf7HI32"
      },
      "source": [
        "def predict(X, parameters):\r\n",
        "    # X here is one training example\r\n",
        "    pred, _, _ = forward_propagation(X, parameters)\r\n",
        "    return pred\r\n",
        "\r\n",
        "def predictions(X, parameters):\r\n",
        "    # X is an array of many training examples\r\n",
        "    y_pred = np.zeros(len(X))\r\n",
        "    for i in range(len(X)):\r\n",
        "        y_pred[i] = np.argmax(predict(X[i], parameters))\r\n",
        "    return y_pred\r\n",
        "        \r\n",
        "def model_accuracy(predictions, y_truth):\r\n",
        "    return np.mean(predictions == y_truth)*100"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsyX8YTHnApP"
      },
      "source": [
        "# Reshaping the array to 4-dims so that it can work with the Keras API\r\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\r\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\r\n",
        "input_shape = (28, 28, 1)\r\n",
        "# Making sure that the values are float so that we can get decimal points after division\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\r\n",
        "X_train /= 255\r\n",
        "X_test /= 255\r\n",
        "\r\n",
        "# Standardize Here"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "b4sja1ytHUP-",
        "outputId": "94455d35-e722-4a5b-ce70-b4db8fc4b332"
      },
      "source": [
        "layer_dims = [input_nodes, 32, 32, 32, output_nodes]\r\n",
        "parameters, epoch_cost = NN_model(X_train, y_train_one_hot, X_test, y_test_one_hot, layer_dims, learning_rate=0.01, max_epochs=20)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current_epoch cost = 1.0218743754545496\n",
            "Current_epoch cost = 0.5425026388026027\n",
            "Current_epoch cost = 0.44806773387393733\n",
            "Current_epoch cost = 0.40351624717352313\n",
            "Current_epoch cost = 0.37698617822801217\n",
            "Current_epoch cost = 0.3586052049920596\n",
            "Current_epoch cost = 0.3445674792872221\n",
            "Current_epoch cost = 0.333204286488785\n",
            "Current_epoch cost = 0.3237006916545765\n",
            "Current_epoch cost = 0.31567403470715294\n",
            "Current_epoch cost = 0.30863123897514466\n",
            "Current_epoch cost = 0.3022728333767004\n",
            "Current_epoch cost = 0.29637303675708637\n",
            "Current_epoch cost = 0.29086409014183007\n",
            "Current_epoch cost = 0.2857540673167312\n",
            "Current_epoch cost = 0.2808548955997404\n",
            "Current_epoch cost = 0.27630916147134854\n",
            "Current_epoch cost = 0.27222571572662047\n",
            "Current_epoch cost = 0.2681693464783418\n",
            "Current_epoch cost = 0.26411541647722364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3nr2axRew7x",
        "outputId": "333dbd55-eb59-496c-d3f8-86e6860ac5bf"
      },
      "source": [
        "epoch_cost"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0218743754545496,\n",
              " 0.5425026388026027,\n",
              " 0.44806773387393733,\n",
              " 0.40351624717352313,\n",
              " 0.37698617822801217,\n",
              " 0.3586052049920596,\n",
              " 0.3445674792872221,\n",
              " 0.333204286488785,\n",
              " 0.3237006916545765,\n",
              " 0.31567403470715294,\n",
              " 0.30863123897514466,\n",
              " 0.3022728333767004,\n",
              " 0.29637303675708637,\n",
              " 0.29086409014183007,\n",
              " 0.2857540673167312,\n",
              " 0.2808548955997404,\n",
              " 0.27630916147134854,\n",
              " 0.27222571572662047,\n",
              " 0.2681693464783418,\n",
              " 0.26411541647722364]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVNG6uwgHZiZ",
        "outputId": "d77de9db-d518-413a-80e9-416be58ef6eb"
      },
      "source": [
        "y_pred_train = predictions(X_train, parameters)\r\n",
        "print(\"Training accuracy = {}%\".format(round(model_accuracy(y_pred_train,y_train), 3)))\r\n",
        "\r\n",
        "y_pred_test = predictions(X_test, parameters)\r\n",
        "print(\"Test accuracy = {}%\".format(round(model_accuracy(y_pred_test, y_test), 3)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy = 90.303%\n",
            "Test accuracy = 86.84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc_kCj24F9SC",
        "outputId": "3da00708-0025-4b0f-c39e-d6f44e68c1e9"
      },
      "source": [
        "y_pred_train"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9., 0., 0., ..., 3., 0., 5.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXXfm4bTF_zS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
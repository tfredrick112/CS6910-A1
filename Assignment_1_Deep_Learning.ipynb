{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Assignment 1 Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPc_chlwW-SQ"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFHth0FqepJf"
      },
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTMduhnXH-I"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVsYdhDPfD7F"
      },
      "source": [
        "(X, y), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "# Reshaping the data matrices\r\n",
        "X = X.reshape(X.shape[0], 784)\r\n",
        "X_test = X_test.reshape(X_test.shape[0], 784)\r\n",
        "\r\n",
        "# Normalizing the pixel intensities\r\n",
        "X = X/255.0\r\n",
        "X_test = X_test/255.0\r\n",
        "\r\n",
        "# Split the X_train into a training set and validation set\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-pqLyGruxa2",
        "outputId": "f197b90c-1234-4466-b4ac-ce72d8590d25"
      },
      "source": [
        "# Number of training examples\r\n",
        "M = X_train.shape[0]\r\n",
        "\r\n",
        "# Number of validation samples\r\n",
        "Mval = X_val.shape[0]\r\n",
        "\r\n",
        "# Number of test examples\r\n",
        "Mtest = X_test.shape[0]\r\n",
        "\r\n",
        "# Number of features in the dataset\r\n",
        "num_features = 784\r\n",
        "\r\n",
        "# Number of classes\r\n",
        "num_classes = len(np.unique(y_train))\r\n",
        "\r\n",
        "# One hot encoding for class labels\r\n",
        "y_train_one_hot = np.zeros((10, M))\r\n",
        "y_train_one_hot[y_train, np.array(list(range(M)))] = 1\r\n",
        "# y_train_one_hot = y_train_one_hot.T\r\n",
        "\r\n",
        "y_val_one_hot = np.zeros((10, Mval))\r\n",
        "y_val_one_hot[y_val, np.array(list(range(Mval)))] = 1\r\n",
        "# y_val_one_hot = y_val_one_hot.T\r\n",
        "\r\n",
        "y_test_one_hot = np.zeros((10, Mtest))\r\n",
        "y_test_one_hot[y_test, np.array(list(range(Mtest)))] = 1\r\n",
        "# y_test_one_hot = y_test_one_hot.T\r\n",
        "\r\n",
        "print(\"Number of images in the training set =\", M)\r\n",
        "print(\"Number of images in the validation set =\", Mval)\r\n",
        "print(\"Number of images in the test set =\", Mtest)\r\n",
        "print(\"Number of classes =\", num_classes)\r\n",
        "print(\"Number of features per example =\", num_features)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the training set = 48000\n",
            "Number of images in the validation set = 12000\n",
            "Number of images in the test set = 10000\n",
            "Number of classes = 10\n",
            "Number of features per example = 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgoEqEwYJ92M"
      },
      "source": [
        "# Modify shapes of the data matrices\r\n",
        "X_train = X_train.T\r\n",
        "X_val = X_val.T\r\n",
        "X_test = X_test.T"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmd4GRMVgBOf"
      },
      "source": [
        "#### Number of neurons in the input and output layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inh6uUzA042P"
      },
      "source": [
        "input_nodes = num_features\r\n",
        "output_nodes = num_classes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpsINbUcepJn"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1. / (1.+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1-sigmoid(x))\n",
        "\n",
        "def Relu(x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "def Relu_derivative(x):\n",
        "    return 1*(x>0) \n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return (1 - (np.tanh(x)**2))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "#cross-entropy for our cost function\n",
        "def compute_multiclass_loss(Y, Y_hat, batch_size, lamb, parameters):\n",
        "    L = (-1.0 * np.sum(np.multiply(Y, np.log(Y_hat))))/batch_size\n",
        "\n",
        "    acc = 0\n",
        "    for i in range(1, len(parameters)//2 + 1):\n",
        "        acc += np.sum(parameters[\"W\"+str(i)]**2)\n",
        "\n",
        "    L = L + (lamb/(2*batch_size))*acc\n",
        "\n",
        "    return L"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx8zxiVlepJo"
      },
      "source": [
        "def initialize_parameters(layer_dims, init_mode=\"xavier\"):\n",
        "    np.random.seed(42)\n",
        "    params = {}\n",
        "    previous_updates = {}\n",
        "    for i in range(1, len(layer_dims)):\n",
        "        if init_mode == 'random_normal':\n",
        "            params[\"W\"+str(i)] = np.random.randn(layer_dims[i], layer_dims[i-1]) * 0.01\n",
        "        elif init_mode == 'random_uniform':\n",
        "            params[\"W\"+str(i)] = np.random.rand(layer_dims[i], layer_dims[i-1]) * 0.01\n",
        "        elif init_mode == 'xavier':\n",
        "            params[\"W\"+str(i)]= np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(2/(layer_dims[i]+layer_dims[i-1]))\n",
        "            \n",
        "        params[\"b\"+str(i)] = np.zeros((layer_dims[i], 1))\n",
        "        \n",
        "        previous_updates[\"W\"+str(i)] = np.zeros((layer_dims[i], layer_dims[i-1]))\n",
        "        previous_updates[\"b\"+str(i)] = np.zeros((layer_dims[i], 1))\n",
        "\n",
        "    return params,previous_updates"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwdBYy5HepJp"
      },
      "source": [
        "def forward_propagate(X, params, activation_f):\n",
        "    L = len(params)//2 + 1\n",
        "    A = [None]*L # activations\n",
        "    Z = [None]*L # pre-activations\n",
        "    \n",
        "    A[0] = X\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        W = params[\"W\"+str(l)]\n",
        "        b = params[\"b\"+str(l)]\n",
        "        \n",
        "        Z[l] = np.matmul(W,A[l-1]) + b\n",
        "        \n",
        "        if l == L-1:\n",
        "            A[l] = softmax(Z[l]) # activation function for output layer\n",
        "        else:\n",
        "            if activation_f == 'sigmoid':\n",
        "                A[l] = sigmoid(Z[l])\n",
        "            elif activation_f == 'relu':\n",
        "                A[l] = Relu(Z[l])\n",
        "            elif activation_f == 'tanh':\n",
        "                A[l] = tanh(Z[l])\n",
        "                \n",
        "    output = A[L-1]\n",
        "\n",
        "    return output,A,Z"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMxm3roOepJp"
      },
      "source": [
        "def backprop(y_hat,y,A,Z,params,activation_f, batch_size, lamb):\n",
        "    L = len(params)//2\n",
        "    gradients = {}\n",
        "    \n",
        "    gradients[\"dZ\"+str(L)] = A[L]-y\n",
        "    \n",
        "    for l in range(L,0,-1):\n",
        "        gradients[\"dW\" + str(l)] = (np.dot(gradients[\"dZ\" + str(l)], A[l-1].T) + lamb*params[\"W\"+str(l)]) / batch_size\n",
        "        gradients[\"db\" + str(l)] = np.sum(gradients[\"dZ\" + str(l)], axis=1,keepdims=True) / batch_size\n",
        "        \n",
        "        if l>1:\n",
        "            if activation_f == 'sigmoid':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * sigmoid_derivative(Z[l-1])\n",
        "            elif activation_f == 'relu':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * Relu_derivative(Z[l-1])\n",
        "            elif activation_f == 'tanh':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * tanh_derivative(Z[l-1])\n",
        "        \n",
        "    return gradients"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voUasFGaepJq"
      },
      "source": [
        "def update_params_sgd(parameters,grads,learning_rate):\n",
        "    L = len(parameters) // 2 \n",
        "    \n",
        "    for l in range(1, L + 1):\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)]\n",
        "\n",
        "    return parameters\n",
        "\n",
        "def update_parameters_momentum(parameters, grads, learning_rate, beta, previous_updates):\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        previous_updates[\"W\"+str(l)] = beta*previous_updates[\"W\"+str(l)] + (1-beta)*grads[\"dW\" + str(l)]\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*previous_updates[\"W\"+str(l)]\n",
        "        \n",
        "        previous_updates[\"b\"+str(l)] = beta*previous_updates[\"b\"+str(l)] + (1-beta)*grads[\"db\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate*previous_updates[\"b\"+str(l)]\n",
        "\n",
        "    return parameters, previous_updates\n",
        "    \n",
        "def update_parameters_RMSprop(parameters, grads, learning_rate, beta, v):\n",
        "\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "    delta = 1e-6 #for numerical stability\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        vdw = beta*v[\"W\" + str(l)] + (1-beta)*np.multiply(grads[\"dW\" + str(l)],grads[\"dW\" + str(l)])\n",
        "        vdb = beta*v[\"b\" + str(l)] + (1-beta)*np.multiply(grads[\"db\" + str(l)],grads[\"db\" + str(l)])\n",
        "\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)] / (np.sqrt(vdw)+delta)\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)] / (np.sqrt(vdb)+delta)\n",
        "\n",
        "        v[\"W\" + str(l)] = vdw\n",
        "        v[\"b\" + str(l)] = vdb\n",
        "\n",
        "    return parameters,v"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8dH__MXepJr"
      },
      "source": [
        "def plot_cost_curve(train_costs, val_costs):\n",
        "    plt.plot(list(range(len(train_costs))), train_costs, 'r', label=\"Training loss\")\n",
        "    plt.plot(list(range(len(val_costs))), val_costs, 'lime', label=\"Validation loss\")\n",
        "    plt.title(\"Training and Validation Loss vs Number of Epochs\", size=16)\n",
        "    plt.xlabel(\"Number of epochs\", size=14)\n",
        "    plt.ylabel(\"Loss\", size=14)\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeBfCkhEepJs"
      },
      "source": [
        "def NN_fit(X,y,X_val,y_val,layer_dims,learning_rate=0.01, activation_f='sigmoid', init_mode='xavier', optimizer = 'sgd', batch_size=512, epochs=100, beta=0.9, L2_lamb=0):\n",
        "    params, previous_updates = initialize_parameters(layer_dims,init_mode)\n",
        "    \n",
        "    epoch_cost = []\n",
        "    validation_epoch_cost = []\n",
        "\n",
        "    params_look_ahead = params.copy()\n",
        "    \n",
        "    count = 1\n",
        "    while count<=epochs:\n",
        "        \n",
        "        count = count + 1 # increment the number of epochs\n",
        "        for i in range(0, X.shape[1], batch_size):\n",
        "            batch_count = batch_size\n",
        "            if i + batch_size > X.shape[1]: # the last mini-batch might contain fewer than \"batch_size\" examples\n",
        "                batch_count = X.shape[1] - i + 1\n",
        "\n",
        "            if optimizer == 'nesterov':\n",
        "                L = len(params)//2\n",
        "                for l in range(1, L+1):\n",
        "                    params_look_ahead[\"W\"+str(l)] = params[\"W\"+str(l)] - beta*previous_updates[\"W\"+str(l)]\n",
        "                    params_look_ahead[\"b\"+str(l)] = params[\"b\"+str(l)] - beta*previous_updates[\"b\"+str(l)]\n",
        "                    \n",
        "                output,A,Z = forward_propagate(X[:,i:i+batch_size],params_look_ahead,activation_f)\n",
        "                gradients = backprop(output,y[:,i:i+batch_size],A,Z,params_look_ahead,activation_f, batch_count, L2_lamb)\n",
        "                params,previous_updates = update_parameters_momentum(params, gradients, learning_rate, beta, previous_updates)\n",
        "                \n",
        "            else:\n",
        "                output,A,Z = forward_propagate(X[:,i:i+batch_size],params,activation_f)\n",
        "                gradients = backprop(output,y[:,i:i+batch_size],A,Z,params,activation_f, batch_count, L2_lamb)\n",
        "\n",
        "                if optimizer == 'sgd':\n",
        "                    params = update_params_sgd(params,gradients,learning_rate)\n",
        "                if optimizer == 'momentum':\n",
        "                    params,previous_updates = update_parameters_momentum(params, gradients, learning_rate, beta, previous_updates)\n",
        "                if optimizer == 'RMSprop':\n",
        "                    params,previous_updates = update_parameters_RMSprop(params, gradients, learning_rate, beta, previous_updates)\n",
        "\n",
        "        # Mean loss for the full training set\n",
        "        full_output, _, _ = forward_propagate(X, params, activation_f)\n",
        "        cost = compute_multiclass_loss(y, full_output, M, L2_lamb, params)\n",
        "        epoch_cost.append(cost)\n",
        "        \n",
        "        # Mean loss for the validation set\n",
        "        out, _, _ = forward_propagate(X_val, params, activation_f)\n",
        "        val_cost = compute_multiclass_loss(y_val, out, Mval, L2_lamb, params)\n",
        "        validation_epoch_cost.append(val_cost)\n",
        "\n",
        "        if (count % 2 == 0):\n",
        "            print(\"Epoch number : {}\".format(count))\n",
        "            print(\"Training cost: \", cost, \"\\tValidation cost:\",val_cost)\n",
        "\n",
        "    print(\"\\nFinal training cost:\", cost)\n",
        "    \n",
        "    # Plot the training and validation cost curves\n",
        "    plot_cost_curve(epoch_cost, validation_epoch_cost)\n",
        "    \n",
        "    return params, epoch_cost"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAH95JS2epJt"
      },
      "source": [
        "def NN_predict(X_test, params, activation_f):\n",
        "    output, _, _ = forward_propagate(X_test, params, activation_f)\n",
        "    predictions = np.argmax(output, axis=0)\n",
        "    return predictions\n",
        "    \n",
        "# def NN_evaluate(Y_hat, Y_test):\n",
        "#     predictions = np.argmax(Y_hat, axis=0)\n",
        "#     labels = np.argmax(Y_test, axis=0)\n",
        "#     return labels\n",
        "\n",
        "def NN_evaluate(X_train, y_train, X_test, y_test, params, activation_f):\n",
        "    train_predictions= NN_predict(X_train, params, activation_f)\n",
        "    test_predictions = NN_predict(X_test, params, activation_f)\n",
        "\n",
        "    print(\"Training accuracy = {} %\".format(round(accuracy_score(y_train, train_predictions) * 100), 3))\n",
        "    print(\"Test accuracy = {} %\".format(round(accuracy_score(y_test, test_predictions) * 100), 3))\n",
        "\n",
        "    print(\"Classification report for the test set:\\n\")\n",
        "    print(classification_report(y_test, test_predictions))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4BS33z5fGxC"
      },
      "source": [
        "#### Setting Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeimiMDf2mjH"
      },
      "source": [
        "layer_dims= [input_nodes,64,64,output_nodes]\r\n",
        "INITIALIZER = \"random_normal\"\r\n",
        "ACTIVATION = \"relu\"\r\n",
        "BATCH_SIZE = 512\r\n",
        "LEARNING_RATE = 0.1\r\n",
        "OPTIMIZER = \"sgd\"\r\n",
        "EPOCHS = 50\r\n",
        "L2_lambda = 0.1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMCGMdn8fJd1"
      },
      "source": [
        "#### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BaT2hbHPe10a",
        "outputId": "0ee41079-7c52-40b3-a1c7-d874bc0cee2f"
      },
      "source": [
        "learned_parameters, epoch_cost = NN_fit(X_train, y_train_one_hot, X_val, y_val_one_hot, \r\n",
        "                            layer_dims, LEARNING_RATE, ACTIVATION, INITIALIZER,\r\n",
        "                            OPTIMIZER, BATCH_SIZE, EPOCHS, L2_lambda)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number : 2\n",
            "Training cost:  2.30146469619724 \tValidation cost: 2.30149219048684\n",
            "Epoch number : 4\n",
            "Training cost:  1.404990822765885 \tValidation cost: 1.4130501692849815\n",
            "Epoch number : 6\n",
            "Training cost:  0.8722884244453614 \tValidation cost: 0.8828207015005022\n",
            "Epoch number : 8\n",
            "Training cost:  0.7983585784045695 \tValidation cost: 0.8110948040965184\n",
            "Epoch number : 10\n",
            "Training cost:  0.7379014476757235 \tValidation cost: 0.7544560201956959\n",
            "Epoch number : 12\n",
            "Training cost:  0.6816697525671606 \tValidation cost: 0.7010172582273115\n",
            "Epoch number : 14\n",
            "Training cost:  0.6130618735373121 \tValidation cost: 0.6326888718239514\n",
            "Epoch number : 16\n",
            "Training cost:  0.557772797668339 \tValidation cost: 0.5774607323841175\n",
            "Epoch number : 18\n",
            "Training cost:  0.5122199424418532 \tValidation cost: 0.5317063517105092\n",
            "Epoch number : 20\n",
            "Training cost:  0.47775514777568584 \tValidation cost: 0.49753077210672497\n",
            "Epoch number : 22\n",
            "Training cost:  0.4512313957454355 \tValidation cost: 0.4717417714298999\n",
            "Epoch number : 24\n",
            "Training cost:  0.43178299149694765 \tValidation cost: 0.45313224393752427\n",
            "Epoch number : 26\n",
            "Training cost:  0.4205569048031506 \tValidation cost: 0.4432329244380696\n",
            "Epoch number : 28\n",
            "Training cost:  0.4133373714846182 \tValidation cost: 0.4372492226626834\n",
            "Epoch number : 30\n",
            "Training cost:  0.40310653530193047 \tValidation cost: 0.42837748598139336\n",
            "Epoch number : 32\n",
            "Training cost:  0.4008824766714321 \tValidation cost: 0.42782212665727887\n",
            "Epoch number : 34\n",
            "Training cost:  0.40365267035878377 \tValidation cost: 0.4320642271934527\n",
            "Epoch number : 36\n",
            "Training cost:  0.4036349224820462 \tValidation cost: 0.43360505011258327\n",
            "Epoch number : 38\n",
            "Training cost:  0.3925769517446745 \tValidation cost: 0.4241711464059932\n",
            "Epoch number : 40\n",
            "Training cost:  0.3723649913813913 \tValidation cost: 0.40550109235467985\n",
            "Epoch number : 42\n",
            "Training cost:  0.4153813219146025 \tValidation cost: 0.45047143866421013\n",
            "Epoch number : 44\n",
            "Training cost:  0.4025248764555401 \tValidation cost: 0.4391466359921588\n",
            "Epoch number : 46\n",
            "Training cost:  0.38851216692697677 \tValidation cost: 0.426881975966618\n",
            "Epoch number : 48\n",
            "Training cost:  0.5458203472827704 \tValidation cost: 0.5863112292268464\n",
            "Epoch number : 50\n",
            "Training cost:  0.41097463933478656 \tValidation cost: 0.4533918002802167\n",
            "\n",
            "Final training cost: 0.35175155323084817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woXJqKNsfLVa"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWj7qtnje7Sg",
        "outputId": "ac181296-bb76-46ac-c8a2-324f979b1da6"
      },
      "source": [
        "NN_evaluate(X_train, y_train, X_test, y_test, learned_parameters, ACTIVATION)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy = 87 %\n",
            "Test accuracy = 85 %\n",
            "Classification report for the test set:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82      1000\n",
            "           1       0.98      0.96      0.97      1000\n",
            "           2       0.84      0.64      0.72      1000\n",
            "           3       0.82      0.92      0.86      1000\n",
            "           4       0.64      0.89      0.74      1000\n",
            "           5       0.98      0.89      0.93      1000\n",
            "           6       0.75      0.47      0.58      1000\n",
            "           7       0.87      0.97      0.92      1000\n",
            "           8       0.94      0.97      0.96      1000\n",
            "           9       0.95      0.94      0.95      1000\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
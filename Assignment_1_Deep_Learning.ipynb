{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Assignment 1 Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPc_chlwW-SQ"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFHth0FqepJf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTMduhnXH-I"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVsYdhDPfD7F"
      },
      "source": [
        "(X, y), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "# Reshaping the data matrices\r\n",
        "X = X.reshape(X.shape[0], 784)\r\n",
        "X_test = X_test.reshape(X_test.shape[0], 784)\r\n",
        "\r\n",
        "# Normalizing the pixel intensities\r\n",
        "X = X/255.0\r\n",
        "X_test = X_test/255.0\r\n",
        "\r\n",
        "# Split the X_train into a training set and validation set\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-pqLyGruxa2",
        "outputId": "ad79bedc-21cd-4840-ae11-d1b85a61fcfe"
      },
      "source": [
        "# Number of training examples\r\n",
        "M = X_train.shape[0]\r\n",
        "\r\n",
        "# Number of validation samples\r\n",
        "Mval = X_val.shape[0]\r\n",
        "\r\n",
        "# Number of test examples\r\n",
        "Mtest = X_test.shape[0]\r\n",
        "\r\n",
        "# Number of features in the dataset\r\n",
        "num_features = 784\r\n",
        "\r\n",
        "# Number of classes\r\n",
        "num_classes = len(np.unique(y_train))\r\n",
        "\r\n",
        "# One hot encoding for class labels\r\n",
        "y_train_one_hot = np.zeros((10, M))\r\n",
        "y_train_one_hot[y_train, np.array(list(range(M)))] = 1\r\n",
        "# y_train_one_hot = y_train_one_hot.T\r\n",
        "\r\n",
        "y_val_one_hot = np.zeros((10, Mval))\r\n",
        "y_val_one_hot[y_val, np.array(list(range(Mval)))] = 1\r\n",
        "# y_val_one_hot = y_val_one_hot.T\r\n",
        "\r\n",
        "y_test_one_hot = np.zeros((10, Mtest))\r\n",
        "y_test_one_hot[y_test, np.array(list(range(Mtest)))] = 1\r\n",
        "# y_test_one_hot = y_test_one_hot.T\r\n",
        "\r\n",
        "print(\"Number of images in the training set =\", M)\r\n",
        "print(\"Number of images in the validation set =\", Mval)\r\n",
        "print(\"Number of images in the test set =\", Mtest)\r\n",
        "print(\"Number of classes =\", num_classes)\r\n",
        "print(\"Number of features per example =\", num_features)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the training set = 54000\n",
            "Number of images in the validation set = 6000\n",
            "Number of images in the test set = 10000\n",
            "Number of classes = 10\n",
            "Number of features per example = 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgoEqEwYJ92M"
      },
      "source": [
        "# Modify shapes of the data matrices\r\n",
        "X_train = X_train.T\r\n",
        "X_val = X_val.T\r\n",
        "X_test = X_test.T"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmd4GRMVgBOf"
      },
      "source": [
        "#### Number of neurons in the input and output layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inh6uUzA042P"
      },
      "source": [
        "input_nodes = num_features\r\n",
        "output_nodes = num_classes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpsINbUcepJn"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1. / (1.+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1-sigmoid(x))\n",
        "\n",
        "def Relu(x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "def Relu_derivative(x):\n",
        "    return 1*(x>0) \n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return (1 - (np.tanh(x)**2))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "#cross-entropy for our cost function\n",
        "def compute_multiclass_loss(Y, Y_hat, batch_size, lamb, parameters):\n",
        "    L = (-1.0 * np.sum(np.multiply(Y, np.log(Y_hat))))/batch_size\n",
        "\n",
        "    acc = 0\n",
        "    for i in range(1, len(parameters)//2 + 1):\n",
        "        acc += np.sum(parameters[\"W\"+str(i)]**2)\n",
        "\n",
        "    L = L + (lamb/(2*batch_size))*acc\n",
        "\n",
        "    return L"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx8zxiVlepJo"
      },
      "source": [
        "def initialize_parameters(layer_dims, init_mode=\"xavier\"):\n",
        "    np.random.seed(42)\n",
        "    params = {}\n",
        "    previous_updates = {}\n",
        "    for i in range(1, len(layer_dims)):\n",
        "        if init_mode == 'random_normal':\n",
        "            params[\"W\"+str(i)] = np.random.randn(layer_dims[i], layer_dims[i-1]) * 0.01\n",
        "        elif init_mode == 'random_uniform':\n",
        "            params[\"W\"+str(i)] = np.random.rand(layer_dims[i], layer_dims[i-1]) * 0.01\n",
        "        elif init_mode == 'xavier':\n",
        "            params[\"W\"+str(i)]= np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(2/(layer_dims[i]+layer_dims[i-1]))\n",
        "            \n",
        "        params[\"b\"+str(i)] = np.zeros((layer_dims[i], 1))\n",
        "        \n",
        "        previous_updates[\"W\"+str(i)] = np.zeros((layer_dims[i], layer_dims[i-1]))\n",
        "        previous_updates[\"b\"+str(i)] = np.zeros((layer_dims[i], 1))\n",
        "\n",
        "    return params,previous_updates"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwdBYy5HepJp"
      },
      "source": [
        "def forward_propagate(X, params, activation_f):\n",
        "    L = len(params)//2 + 1\n",
        "    A = [None]*L # activations\n",
        "    Z = [None]*L # pre-activations\n",
        "    \n",
        "    A[0] = X\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        W = params[\"W\"+str(l)]\n",
        "        b = params[\"b\"+str(l)]\n",
        "        \n",
        "        Z[l] = np.matmul(W,A[l-1]) + b\n",
        "        \n",
        "        if l == L-1:\n",
        "            A[l] = softmax(Z[l]) # activation function for output layer\n",
        "        else:\n",
        "            if activation_f == 'sigmoid':\n",
        "                A[l] = sigmoid(Z[l])\n",
        "            elif activation_f == 'relu':\n",
        "                A[l] = Relu(Z[l])\n",
        "            elif activation_f == 'tanh':\n",
        "                A[l] = tanh(Z[l])\n",
        "                \n",
        "    output = A[L-1]\n",
        "\n",
        "    return output,A,Z"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMxm3roOepJp"
      },
      "source": [
        "def backprop(y_hat, y,A, Z, params, activation_f, batch_size, lamb):\n",
        "    L = len(params)//2\n",
        "    gradients = {}\n",
        "    \n",
        "    gradients[\"dZ\"+str(L)] = A[L]-y\n",
        "    \n",
        "    for l in range(L,0,-1):\n",
        "        gradients[\"dW\" + str(l)] = (np.dot(gradients[\"dZ\" + str(l)], A[l-1].T) + lamb*params[\"W\"+str(l)]) / batch_size\n",
        "        gradients[\"db\" + str(l)] = np.sum(gradients[\"dZ\" + str(l)], axis=1, keepdims=True) / batch_size\n",
        "        \n",
        "        if l>1:\n",
        "            if activation_f == 'sigmoid':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * sigmoid_derivative(Z[l-1])\n",
        "            elif activation_f == 'relu':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * Relu_derivative(Z[l-1])\n",
        "            elif activation_f == 'tanh':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * tanh_derivative(Z[l-1])\n",
        "        \n",
        "    return gradients"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voUasFGaepJq"
      },
      "source": [
        "def update_params_sgd(parameters,grads,learning_rate):\n",
        "    L = len(parameters) // 2 \n",
        "    \n",
        "    for l in range(1, L + 1):\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)]\n",
        "\n",
        "    return parameters\n",
        "\n",
        "def update_parameters_momentum(parameters, grads, learning_rate, beta, previous_updates):\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        previous_updates[\"W\"+str(l)] = beta*previous_updates[\"W\"+str(l)] + (1-beta)*grads[\"dW\" + str(l)]\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*previous_updates[\"W\"+str(l)]\n",
        "        \n",
        "        previous_updates[\"b\"+str(l)] = beta*previous_updates[\"b\"+str(l)] + (1-beta)*grads[\"db\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate*previous_updates[\"b\"+str(l)]\n",
        "\n",
        "    return parameters, previous_updates\n",
        "    \n",
        "def update_parameters_RMSprop(parameters, grads, learning_rate, beta, v):\n",
        "\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "    delta = 1e-6 # for numerical stability\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        vdw = beta*v[\"W\" + str(l)] + (1-beta)*np.multiply(grads[\"dW\" + str(l)],grads[\"dW\" + str(l)])\n",
        "        vdb = beta*v[\"b\" + str(l)] + (1-beta)*np.multiply(grads[\"db\" + str(l)],grads[\"db\" + str(l)])\n",
        "\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)] / (np.sqrt(vdw)+delta)\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)] / (np.sqrt(vdb)+delta)\n",
        "\n",
        "        v[\"W\" + str(l)] = vdw\n",
        "        v[\"b\" + str(l)] = vdb\n",
        "\n",
        "    return parameters,v\n",
        "\n",
        "def update_parameters_adam(parameters, grads, learning_rate, v, m, t):\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for l in range(1, L+1):\n",
        "        mdw = beta1*m[\"W\"+str(l)] + (1-beta1)*grads[\"dW\"+str(l)]\n",
        "        vdw = beta2*v[\"W\"+str(l)] + (1-beta2)*np.square(grads[\"dW\"+str(l)])\n",
        "        mw_hat = mdw/(1.0 - beta1**t)\n",
        "        vw_hat = vdw/(1.0 - beta2**t)\n",
        "\n",
        "        parameters[\"W\"+str(l)] = parameters[\"W\"+str(l)] - (learning_rate * mw_hat)/np.sqrt(vw_hat + epsilon)\n",
        "\n",
        "        mdb = beta1*m[\"b\"+str(l)] + (1-beta1)*grads[\"db\"+str(l)]\n",
        "        vdb = beta2*v[\"b\"+str(l)] + (1-beta2)*np.square(grads[\"db\"+str(l)])\n",
        "        mb_hat = mdb/(1.0 - beta1**t)\n",
        "        vb_hat = vdb/(1.0 - beta2**t)\n",
        "\n",
        "        parameters[\"b\"+str(l)] = parameters[\"b\"+str(l)] - (learning_rate * mb_hat)/np.sqrt(vb_hat + epsilon)\n",
        "\n",
        "        v[\"dW\"+str(l)] = vdw\n",
        "        m[\"dW\"+str(l)] = mdw\n",
        "        v[\"db\"+str(l)] = vdb\n",
        "        m[\"db\"+str(l)] = mdb\n",
        "\n",
        "    t = t + 1 # timestep\n",
        "    return parameters, v, m, t"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8dH__MXepJr"
      },
      "source": [
        "def plot_cost_curve(train_costs, val_costs):\n",
        "    plt.plot(list(range(len(train_costs))), train_costs, 'r', label=\"Training loss\")\n",
        "    plt.plot(list(range(len(val_costs))), val_costs, 'lime', label=\"Validation loss\")\n",
        "    plt.title(\"Training and Validation Loss vs Number of Epochs\", size=16)\n",
        "    plt.xlabel(\"Number of epochs\", size=14)\n",
        "    plt.ylabel(\"Loss\", size=14)\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeBfCkhEepJs"
      },
      "source": [
        "def NN_fit(X,y,X_val,y_val,layer_dims,learning_rate=0.01, activation_f='sigmoid', init_mode='xavier', optimizer = 'sgd', batch_size=512, epochs=100, beta=0.9, L2_lamb=0):\n",
        "    params, previous_updates = initialize_parameters(layer_dims,init_mode)\n",
        "    \n",
        "    epoch_cost = []\n",
        "    validation_epoch_cost = []\n",
        "\n",
        "    params_look_ahead = params.copy() # initialization for nestorov\n",
        "    \n",
        "    count = 1\n",
        "\n",
        "    t = 1 # initialize timestep for Adam optimizer\n",
        "    v = previous_updates.copy()\n",
        "    m = previous_updates.copy()\n",
        "\n",
        "    while count<=epochs:\n",
        "        count = count + 1 # increment the number of epochs\n",
        "        for i in range(0, X.shape[1], batch_size):\n",
        "            batch_count = batch_size\n",
        "            if i + batch_size > X.shape[1]: # the last mini-batch might contain fewer than \"batch_size\" examples\n",
        "                batch_count = X.shape[1] - i + 1\n",
        "\n",
        "            if optimizer == 'nesterov':\n",
        "                L = len(params)//2\n",
        "                for l in range(1, L+1):\n",
        "                    params_look_ahead[\"W\"+str(l)] = params[\"W\"+str(l)] - beta*previous_updates[\"W\"+str(l)]\n",
        "                    params_look_ahead[\"b\"+str(l)] = params[\"b\"+str(l)] - beta*previous_updates[\"b\"+str(l)]\n",
        "                    \n",
        "                output,A,Z = forward_propagate(X[:,i:i+batch_size],params_look_ahead,activation_f)\n",
        "                gradients = backprop(output,y[:,i:i+batch_size],A,Z,params_look_ahead,activation_f, batch_count, L2_lamb)\n",
        "                params,previous_updates = update_parameters_momentum(params, gradients, learning_rate, beta, previous_updates)\n",
        "                \n",
        "            elif optimizer=='nadam':\n",
        "                L = len(params)//2\n",
        "                \n",
        "\n",
        "            else:\n",
        "                output,A,Z = forward_propagate(X[:,i:i+batch_size],params,activation_f)\n",
        "                gradients = backprop(output,y[:,i:i+batch_size],A,Z,params,activation_f, batch_count, L2_lamb)\n",
        "\n",
        "                if optimizer == 'sgd':\n",
        "                    params = update_params_sgd(params,gradients,learning_rate)\n",
        "                elif optimizer == 'momentum':\n",
        "                    params,previous_updates = update_parameters_momentum(params, gradients, learning_rate, beta, previous_updates)\n",
        "                elif optimizer == 'RMSprop':\n",
        "                    params,previous_updates = update_parameters_RMSprop(params, gradients, learning_rate, beta, previous_updates)\n",
        "                elif optimizer == 'adam':\n",
        "                    params, v, m, t = update_parameters_adam(params, gradients, learning_rate, v, m, t)\n",
        "\n",
        "        # Mean loss for the full training set\n",
        "        full_output, _, _ = forward_propagate(X, params, activation_f)\n",
        "        cost = compute_multiclass_loss(y, full_output, M, L2_lamb, params)\n",
        "        epoch_cost.append(cost)\n",
        "        \n",
        "        # Mean loss for the validation set\n",
        "        out, _, _ = forward_propagate(X_val, params, activation_f)\n",
        "        val_cost = compute_multiclass_loss(y_val, out, Mval, L2_lamb, params)\n",
        "        validation_epoch_cost.append(val_cost)\n",
        "\n",
        "        if (count % 2 == 0):\n",
        "            print(\"Epoch number : {}\".format(count))\n",
        "            print(\"Training cost: \", cost, \"\\tValidation cost:\",val_cost)\n",
        "\n",
        "    print(\"\\nFinal training cost:\", cost)\n",
        "    \n",
        "    # Plot the training and validation cost curves\n",
        "    plot_cost_curve(epoch_cost, validation_epoch_cost)\n",
        "    \n",
        "    return params, epoch_cost"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAH95JS2epJt"
      },
      "source": [
        "def NN_predict(X_test, params, activation_f):\n",
        "    output, _, _ = forward_propagate(X_test, params, activation_f)\n",
        "    predictions = np.argmax(output, axis=0)\n",
        "    return predictions\n",
        "\n",
        "def NN_evaluate(X_train, y_train, X_test, y_test, params, activation_f):\n",
        "    train_predictions= NN_predict(X_train, params, activation_f)\n",
        "    test_predictions = NN_predict(X_test, params, activation_f)\n",
        "\n",
        "    print(\"Training accuracy = {} %\".format(round(accuracy_score(y_train, train_predictions) * 100), 3))\n",
        "    print(\"Test accuracy = {} %\".format(round(accuracy_score(y_test, test_predictions) * 100), 3))\n",
        "\n",
        "    print(\"Classification report for the test set:\\n\")\n",
        "    print(classification_report(y_test, test_predictions))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4BS33z5fGxC"
      },
      "source": [
        "#### Setting Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeimiMDf2mjH"
      },
      "source": [
        "layer_dims= [input_nodes,64,64,output_nodes]\r\n",
        "INITIALIZER = \"xavier\"\r\n",
        "ACTIVATION = \"relu\"\r\n",
        "BATCH_SIZE = 128\r\n",
        "LEARNING_RATE = 0.0001\r\n",
        "OPTIMIZER = \"adam\"\r\n",
        "EPOCHS = 50\r\n",
        "L2_lambda = 0.5"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMCGMdn8fJd1"
      },
      "source": [
        "#### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BaT2hbHPe10a",
        "outputId": "c9780866-c12c-4fdc-869b-5438281111b4"
      },
      "source": [
        "learned_parameters, epoch_cost = NN_fit(X_train, y_train_one_hot, X_val, y_val_one_hot, \r\n",
        "                            layer_dims, LEARNING_RATE, ACTIVATION, INITIALIZER,\r\n",
        "                            OPTIMIZER, BATCH_SIZE, EPOCHS, L2_lambda)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number : 2\n",
            "Training cost:  0.6775779832038746 \tValidation cost: 0.6896385277210049\n",
            "Epoch number : 4\n",
            "Training cost:  0.46844682099753904 \tValidation cost: 0.4782713402631794\n",
            "Epoch number : 6\n",
            "Training cost:  0.4194351047572022 \tValidation cost: 0.4302249774781835\n",
            "Epoch number : 8\n",
            "Training cost:  0.3916075313767707 \tValidation cost: 0.40538081519753033\n",
            "Epoch number : 10\n",
            "Training cost:  0.37194174597581364 \tValidation cost: 0.38944924188666113\n",
            "Epoch number : 12\n",
            "Training cost:  0.3577290111038397 \tValidation cost: 0.38048924573679377\n",
            "Epoch number : 14\n",
            "Training cost:  0.34702770545279005 \tValidation cost: 0.37495119538073335\n",
            "Epoch number : 16\n",
            "Training cost:  0.337963089422989 \tValidation cost: 0.3712425853917905\n",
            "Epoch number : 18\n",
            "Training cost:  0.3272965104068115 \tValidation cost: 0.3649335796161818\n",
            "Epoch number : 20\n",
            "Training cost:  0.3227095061834175 \tValidation cost: 0.36448179927092905\n",
            "Epoch number : 22\n",
            "Training cost:  0.3158161584247989 \tValidation cost: 0.36209865040846206\n",
            "Epoch number : 24\n",
            "Training cost:  0.30985466359273534 \tValidation cost: 0.3602960688451548\n",
            "Epoch number : 26\n",
            "Training cost:  0.3048213527661742 \tValidation cost: 0.35920749149652875\n",
            "Epoch number : 28\n",
            "Training cost:  0.30022124268401335 \tValidation cost: 0.35920422904408905\n",
            "Epoch number : 30\n",
            "Training cost:  0.2950819635508568 \tValidation cost: 0.35782486387378293\n",
            "Epoch number : 32\n",
            "Training cost:  0.2928712949184164 \tValidation cost: 0.3597747995580359\n",
            "Epoch number : 34\n",
            "Training cost:  0.2888512497727012 \tValidation cost: 0.35929619059793794\n",
            "Epoch number : 36\n",
            "Training cost:  0.2852580921134659 \tValidation cost: 0.3603716004069696\n",
            "Epoch number : 38\n",
            "Training cost:  0.2825621888749317 \tValidation cost: 0.36152899788474385\n",
            "Epoch number : 40\n",
            "Training cost:  0.27905004001310274 \tValidation cost: 0.3619437254479198\n",
            "Epoch number : 42\n",
            "Training cost:  0.2746767407261921 \tValidation cost: 0.3616491950330954\n",
            "Epoch number : 44\n",
            "Training cost:  0.27354925846663125 \tValidation cost: 0.36373498964852624\n",
            "Epoch number : 46\n",
            "Training cost:  0.2720143434359621 \tValidation cost: 0.3659290857643834\n",
            "Epoch number : 48\n",
            "Training cost:  0.2698513926652558 \tValidation cost: 0.36795120750088584\n",
            "Epoch number : 50\n",
            "Training cost:  0.2676070914622585 \tValidation cost: 0.3701635167813246\n",
            "\n",
            "Final training cost: 0.2697340626531058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woXJqKNsfLVa"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWj7qtnje7Sg",
        "outputId": "9d193ac9-18b0-47be-c51e-6c661ba91b0e"
      },
      "source": [
        "NN_evaluate(X_train, y_train, X_test, y_test, learned_parameters, ACTIVATION)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy = 91 %\n",
            "Test accuracy = 87 %\n",
            "Classification report for the test set:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81      1000\n",
            "           1       0.99      0.96      0.97      1000\n",
            "           2       0.72      0.83      0.77      1000\n",
            "           3       0.84      0.91      0.87      1000\n",
            "           4       0.79      0.78      0.78      1000\n",
            "           5       0.97      0.93      0.95      1000\n",
            "           6       0.72      0.64      0.68      1000\n",
            "           7       0.91      0.96      0.93      1000\n",
            "           8       0.96      0.96      0.96      1000\n",
            "           9       0.95      0.95      0.95      1000\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4xvwwJrMqxF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
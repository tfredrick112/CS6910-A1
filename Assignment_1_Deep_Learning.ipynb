{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Assignment 1 Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPc_chlwW-SQ"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFHth0FqepJf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTMduhnXH-I"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVsYdhDPfD7F"
      },
      "source": [
        "(X, y), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "# Reshaping the data matrices\r\n",
        "X = X.reshape(X.shape[0], 784)\r\n",
        "X_test = X_test.reshape(X_test.shape[0], 784)\r\n",
        "\r\n",
        "# Normalizing the pixel intensities\r\n",
        "X = X/255.0\r\n",
        "X_test = X_test/255.0\r\n",
        "\r\n",
        "# Split the X_train into a training set and validation set\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-pqLyGruxa2",
        "outputId": "ad79bedc-21cd-4840-ae11-d1b85a61fcfe"
      },
      "source": [
        "# Number of training examples\r\n",
        "M = X_train.shape[0]\r\n",
        "\r\n",
        "# Number of validation samples\r\n",
        "Mval = X_val.shape[0]\r\n",
        "\r\n",
        "# Number of test examples\r\n",
        "Mtest = X_test.shape[0]\r\n",
        "\r\n",
        "# Number of features in the dataset\r\n",
        "num_features = 784\r\n",
        "\r\n",
        "# Number of classes\r\n",
        "num_classes = len(np.unique(y_train))\r\n",
        "\r\n",
        "# One hot encoding for class labels\r\n",
        "y_train_one_hot = np.zeros((10, M))\r\n",
        "y_train_one_hot[y_train, np.array(list(range(M)))] = 1\r\n",
        "# y_train_one_hot = y_train_one_hot.T\r\n",
        "\r\n",
        "y_val_one_hot = np.zeros((10, Mval))\r\n",
        "y_val_one_hot[y_val, np.array(list(range(Mval)))] = 1\r\n",
        "# y_val_one_hot = y_val_one_hot.T\r\n",
        "\r\n",
        "y_test_one_hot = np.zeros((10, Mtest))\r\n",
        "y_test_one_hot[y_test, np.array(list(range(Mtest)))] = 1\r\n",
        "# y_test_one_hot = y_test_one_hot.T\r\n",
        "\r\n",
        "print(\"Number of images in the training set =\", M)\r\n",
        "print(\"Number of images in the validation set =\", Mval)\r\n",
        "print(\"Number of images in the test set =\", Mtest)\r\n",
        "print(\"Number of classes =\", num_classes)\r\n",
        "print(\"Number of features per example =\", num_features)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the training set = 54000\n",
            "Number of images in the validation set = 6000\n",
            "Number of images in the test set = 10000\n",
            "Number of classes = 10\n",
            "Number of features per example = 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgoEqEwYJ92M"
      },
      "source": [
        "# Modify shapes of the data matrices\r\n",
        "X_train = X_train.T\r\n",
        "X_val = X_val.T\r\n",
        "X_test = X_test.T"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmd4GRMVgBOf"
      },
      "source": [
        "#### Number of neurons in the input and output layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inh6uUzA042P"
      },
      "source": [
        "input_nodes = num_features\r\n",
        "output_nodes = num_classes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpsINbUcepJn"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1. / (1.+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1-sigmoid(x))\n",
        "\n",
        "def Relu(x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "def Relu_derivative(x):\n",
        "    return 1*(x>0) \n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return (1 - (np.tanh(x)**2))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "#cross-entropy for our cost function\n",
        "def compute_multiclass_loss(Y, Y_hat, batch_size, lamb, parameters):\n",
        "    L = (-1.0 * np.sum(np.multiply(Y, np.log(Y_hat))))/batch_size\n",
        "\n",
        "    acc = 0\n",
        "    for i in range(1, len(parameters)//2 + 1):\n",
        "        acc += np.sum(parameters[\"W\"+str(i)]**2)\n",
        "\n",
        "    L = L + (lamb/(2*batch_size))*acc\n",
        "\n",
        "    return L"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx8zxiVlepJo"
      },
      "source": [
        "def initialize_parameters(layer_dims, init_mode=\"xavier\"):\n",
        "    np.random.seed(42)\n",
        "    params = {}\n",
        "    previous_updates = {}\n",
        "    for i in range(1, len(layer_dims)):\n",
        "        if init_mode == 'random_normal':\n",
        "            params[\"W\"+str(i)] = np.random.randn(layer_dims[i], layer_dims[i-1]) * 0.01\n",
        "        elif init_mode == 'random_uniform':\n",
        "            params[\"W\"+str(i)] = np.random.rand(layer_dims[i], layer_dims[i-1]) * 0.01\n",
        "        elif init_mode == 'xavier':\n",
        "            params[\"W\"+str(i)]= np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(2/(layer_dims[i]+layer_dims[i-1]))\n",
        "            \n",
        "        params[\"b\"+str(i)] = np.zeros((layer_dims[i], 1))\n",
        "        \n",
        "        previous_updates[\"W\"+str(i)] = np.zeros((layer_dims[i], layer_dims[i-1]))\n",
        "        previous_updates[\"b\"+str(i)] = np.zeros((layer_dims[i], 1))\n",
        "\n",
        "    return params,previous_updates"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwdBYy5HepJp"
      },
      "source": [
        "def forward_propagate(X, params, activation_f):\n",
        "    L = len(params)//2 + 1\n",
        "    A = [None]*L # activations\n",
        "    Z = [None]*L # pre-activations\n",
        "    \n",
        "    A[0] = X\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        W = params[\"W\"+str(l)]\n",
        "        b = params[\"b\"+str(l)]\n",
        "        \n",
        "        Z[l] = np.matmul(W,A[l-1]) + b\n",
        "        \n",
        "        if l == L-1:\n",
        "            A[l] = softmax(Z[l]) # activation function for output layer\n",
        "        else:\n",
        "            if activation_f == 'sigmoid':\n",
        "                A[l] = sigmoid(Z[l])\n",
        "            elif activation_f == 'relu':\n",
        "                A[l] = Relu(Z[l])\n",
        "            elif activation_f == 'tanh':\n",
        "                A[l] = tanh(Z[l])\n",
        "                \n",
        "    output = A[L-1]\n",
        "\n",
        "    return output,A,Z"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMxm3roOepJp"
      },
      "source": [
        "def backprop(y_hat, y,A, Z, params, activation_f, batch_size, lamb):\n",
        "    L = len(params)//2\n",
        "    gradients = {}\n",
        "    \n",
        "    gradients[\"dZ\"+str(L)] = A[L]-y\n",
        "    \n",
        "    for l in range(L,0,-1):\n",
        "        gradients[\"dW\" + str(l)] = (np.dot(gradients[\"dZ\" + str(l)], A[l-1].T) + lamb*params[\"W\"+str(l)]) / batch_size\n",
        "        gradients[\"db\" + str(l)] = np.sum(gradients[\"dZ\" + str(l)], axis=1, keepdims=True) / batch_size\n",
        "        \n",
        "        if l>1:\n",
        "            if activation_f == 'sigmoid':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * sigmoid_derivative(Z[l-1])\n",
        "            elif activation_f == 'relu':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * Relu_derivative(Z[l-1])\n",
        "            elif activation_f == 'tanh':\n",
        "                gradients[\"dZ\"+str(l-1)] = np.matmul(params[\"W\" + str(l)].T, gradients[\"dZ\" + str(l)]) * tanh_derivative(Z[l-1])\n",
        "        \n",
        "    return gradients"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voUasFGaepJq"
      },
      "source": [
        "def update_params_sgd(parameters,grads,learning_rate):\n",
        "    L = len(parameters) // 2 \n",
        "    \n",
        "    for l in range(1, L + 1):\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)]\n",
        "\n",
        "    return parameters\n",
        "\n",
        "def update_parameters_momentum(parameters, grads, learning_rate, beta, previous_updates):\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        previous_updates[\"W\"+str(l)] = beta*previous_updates[\"W\"+str(l)] + (1-beta)*grads[\"dW\" + str(l)]\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*previous_updates[\"W\"+str(l)]\n",
        "        \n",
        "        previous_updates[\"b\"+str(l)] = beta*previous_updates[\"b\"+str(l)] + (1-beta)*grads[\"db\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate*previous_updates[\"b\"+str(l)]\n",
        "\n",
        "    return parameters, previous_updates\n",
        "    \n",
        "def update_parameters_RMSprop(parameters, grads, learning_rate, beta, v):\n",
        "\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "    delta = 1e-6 # for numerical stability\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        vdw = beta*v[\"W\" + str(l)] + (1-beta)*np.multiply(grads[\"dW\" + str(l)],grads[\"dW\" + str(l)])\n",
        "        vdb = beta*v[\"b\" + str(l)] + (1-beta)*np.multiply(grads[\"db\" + str(l)],grads[\"db\" + str(l)])\n",
        "\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)] / (np.sqrt(vdw)+delta)\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)] / (np.sqrt(vdb)+delta)\n",
        "\n",
        "        v[\"W\" + str(l)] = vdw\n",
        "        v[\"b\" + str(l)] = vdb\n",
        "\n",
        "    return parameters,v\n",
        "\n",
        "def update_parameters_adam(parameters, grads, learning_rate, v, m, t):\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for l in range(1, L+1):\n",
        "        mdw = beta1*m[\"W\"+str(l)] + (1-beta1)*grads[\"dW\"+str(l)]\n",
        "        vdw = beta2*v[\"W\"+str(l)] + (1-beta2)*np.square(grads[\"dW\"+str(l)])\n",
        "        mw_hat = mdw/(1.0 - beta1**t)\n",
        "        vw_hat = vdw/(1.0 - beta2**t)\n",
        "\n",
        "        parameters[\"W\"+str(l)] = parameters[\"W\"+str(l)] - (learning_rate * mw_hat)/np.sqrt(vw_hat + epsilon)\n",
        "\n",
        "        mdb = beta1*m[\"b\"+str(l)] + (1-beta1)*grads[\"db\"+str(l)]\n",
        "        vdb = beta2*v[\"b\"+str(l)] + (1-beta2)*np.square(grads[\"db\"+str(l)])\n",
        "        mb_hat = mdb/(1.0 - beta1**t)\n",
        "        vb_hat = vdb/(1.0 - beta2**t)\n",
        "\n",
        "        parameters[\"b\"+str(l)] = parameters[\"b\"+str(l)] - (learning_rate * mb_hat)/np.sqrt(vb_hat + epsilon)\n",
        "\n",
        "        v[\"dW\"+str(l)] = vdw\n",
        "        m[\"dW\"+str(l)] = mdw\n",
        "        v[\"db\"+str(l)] = vdb\n",
        "        m[\"db\"+str(l)] = mdb\n",
        "\n",
        "    t = t + 1 # timestep\n",
        "    return parameters, v, m, t"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8dH__MXepJr"
      },
      "source": [
        "def plot_cost_curve(train_costs, val_costs):\n",
        "    plt.plot(list(range(len(train_costs))), train_costs, 'r', label=\"Training loss\")\n",
        "    plt.plot(list(range(len(val_costs))), val_costs, 'lime', label=\"Validation loss\")\n",
        "    plt.title(\"Training and Validation Loss vs Number of Epochs\", size=16)\n",
        "    plt.xlabel(\"Number of epochs\", size=14)\n",
        "    plt.ylabel(\"Loss\", size=14)\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeBfCkhEepJs"
      },
      "source": [
        "def NN_fit(X,y,X_val,y_val,layer_dims,learning_rate=0.01, activation_f='sigmoid', init_mode='xavier', optimizer = 'sgd', batch_size=512, epochs=10, beta=0.9, L2_lamb=0):\n",
        "\n",
        "    params, previous_updates = initialize_parameters(layer_dims,init_mode)\n",
        "    \n",
        "    epoch_cost = []\n",
        "    validation_epoch_cost = []\n",
        "\n",
        "    params_look_ahead = params.copy() # initialization for nestorov\n",
        "    \n",
        "    count = 1\n",
        "\n",
        "    t = 1 # initialize timestep for Adam optimizer\n",
        "    v = previous_updates.copy()\n",
        "    m = previous_updates.copy()\n",
        "\n",
        "    while count<=epochs:\n",
        "        count = count + 1 # increment the number of epochs\n",
        "        for i in range(0, X.shape[1], batch_size):\n",
        "            batch_count = batch_size\n",
        "            if i + batch_size > X.shape[1]: # the last mini-batch might contain fewer than \"batch_size\" examples\n",
        "                batch_count = X.shape[1] - i + 1\n",
        "\n",
        "            if optimizer == 'nesterov':\n",
        "                L = len(params)//2\n",
        "                for l in range(1, L+1):\n",
        "                    params_look_ahead[\"W\"+str(l)] = params[\"W\"+str(l)] - beta*previous_updates[\"W\"+str(l)]\n",
        "                    params_look_ahead[\"b\"+str(l)] = params[\"b\"+str(l)] - beta*previous_updates[\"b\"+str(l)]\n",
        "                    \n",
        "                output,A,Z = forward_propagate(X[:,i:i+batch_size],params_look_ahead,activation_f)\n",
        "                gradients = backprop(output,y[:,i:i+batch_size],A,Z,params_look_ahead,activation_f, batch_count, L2_lamb)\n",
        "                params,previous_updates = update_parameters_momentum(params, gradients, learning_rate, beta, previous_updates)\n",
        "                \n",
        "            elif optimizer=='nadam':\n",
        "                L = len(params)//2\n",
        "                for l in range(1, L+1):\n",
        "                    params_look_ahead[\"W\"+str(l)] = params[\"W\"+str(l)] - beta*previous_updates[\"W\"+str(l)]\n",
        "                    params_look_ahead[\"b\"+str(l)] = params[\"b\"+str(l)] - beta*previous_updates[\"b\"+str(l)]\n",
        "\n",
        "                output,A,Z = forward_propagate(X[:,i:i+batch_size],params_look_ahead,activation_f)\n",
        "                gradients = backprop(output,y[:,i:i+batch_size],A,Z,params_look_ahead,activation_f, batch_count, L2_lamb)\n",
        "                params, v, m, t = update_parameters_adam(params, gradients, learning_rate, v, m, t)\n",
        "\n",
        "            else:\n",
        "                output,A,Z = forward_propagate(X[:,i:i+batch_size],params,activation_f)\n",
        "                gradients = backprop(output,y[:,i:i+batch_size],A,Z,params,activation_f, batch_count, L2_lamb)\n",
        "\n",
        "                if optimizer == 'sgd':\n",
        "                    params = update_params_sgd(params,gradients,learning_rate)\n",
        "                elif optimizer == 'momentum':\n",
        "                    params,previous_updates = update_parameters_momentum(params, gradients, learning_rate, beta, previous_updates)\n",
        "                elif optimizer == 'RMSprop':\n",
        "                    params,previous_updates = update_parameters_RMSprop(params, gradients, learning_rate, beta, previous_updates)\n",
        "                elif optimizer == 'adam':\n",
        "                    params, v, m, t = update_parameters_adam(params, gradients, learning_rate, v, m, t)\n",
        "\n",
        "        # Mean loss for the full training set\n",
        "        full_output, _, _ = forward_propagate(X, params, activation_f)\n",
        "        cost = compute_multiclass_loss(y, full_output, M, L2_lamb, params)\n",
        "        epoch_cost.append(cost)\n",
        "        \n",
        "        # Mean loss for the validation set\n",
        "        out, _, _ = forward_propagate(X_val, params, activation_f)\n",
        "        val_cost = compute_multiclass_loss(y_val, out, Mval, L2_lamb, params)\n",
        "        validation_epoch_cost.append(val_cost)\n",
        "\n",
        "        if (count % 2 == 0):\n",
        "            print(\"Epoch number : {}\".format(count))\n",
        "            print(\"Training cost: \", cost, \"\\tValidation cost:\",val_cost)\n",
        "\n",
        "    print(\"\\nFinal training cost:\", cost)\n",
        "    \n",
        "    # Plot the training and validation cost curves\n",
        "    plot_cost_curve(epoch_cost, validation_epoch_cost)\n",
        "    \n",
        "    return params, epoch_cost"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAH95JS2epJt"
      },
      "source": [
        "def NN_predict(X_test, params, activation_f):\n",
        "    output, _, _ = forward_propagate(X_test, params, activation_f)\n",
        "    predictions = np.argmax(output, axis=0)\n",
        "    return predictions\n",
        "\n",
        "def NN_evaluate(X_train, y_train, X_test, y_test, params, activation_f):\n",
        "    train_predictions= NN_predict(X_train, params, activation_f)\n",
        "    test_predictions = NN_predict(X_test, params, activation_f)\n",
        "\n",
        "    print(\"Training accuracy = {} %\".format(round(accuracy_score(y_train, train_predictions) * 100), 3))\n",
        "    print(\"Test accuracy = {} %\".format(round(accuracy_score(y_test, test_predictions) * 100), 3))\n",
        "\n",
        "    print(\"Classification report for the test set:\\n\")\n",
        "    print(classification_report(y_test, test_predictions))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4BS33z5fGxC"
      },
      "source": [
        "#### Setting Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeimiMDf2mjH"
      },
      "source": [
        "layer_dims= [input_nodes,64,64,output_nodes]\r\n",
        "LEARNING_RATE = 0.0001\r\n",
        "ACTIVATION = \"relu\"\r\n",
        "INITIALIZER = \"xavier\"\r\n",
        "OPTIMIZER = \"nadam\"\r\n",
        "BATCH_SIZE = 128\r\n",
        "EPOCHS = 50\r\n",
        "BETA = 0.9\r\n",
        "L2_lambda = 0.5"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMCGMdn8fJd1"
      },
      "source": [
        "#### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BaT2hbHPe10a",
        "outputId": "f1196626-5331-4025-da6d-5fce0f1e5d37"
      },
      "source": [
        "learned_parameters, epoch_cost = NN_fit(X_train, y_train_one_hot, X_val, y_val_one_hot, layer_dims,\r\n",
        "                            learning_rate=LEARNING_RATE,\r\n",
        "                            activation_f = ACTIVATION,\r\n",
        "                            init_mode = INITIALIZER,\r\n",
        "                            optimizer = OPTIMIZER,\r\n",
        "                            batch_size = BATCH_SIZE,\r\n",
        "                            epochs = EPOCHS,\r\n",
        "                            beta = BETA,\r\n",
        "                            L2_lamb = L2_lambda)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number : 2\n",
            "Training cost:  0.6873994056420121 \tValidation cost: 0.7065422997011096\n",
            "Epoch number : 4\n",
            "Training cost:  0.48385102459262064 \tValidation cost: 0.49944565821163217\n",
            "Epoch number : 6\n",
            "Training cost:  0.4403786665671225 \tValidation cost: 0.45528250339679366\n",
            "Epoch number : 8\n",
            "Training cost:  0.418904849610682 \tValidation cost: 0.4342325982201712\n",
            "Epoch number : 10\n",
            "Training cost:  0.40401244167596556 \tValidation cost: 0.4205197937722067\n",
            "Epoch number : 12\n",
            "Training cost:  0.3939052367428079 \tValidation cost: 0.4120405307449472\n",
            "Epoch number : 14\n",
            "Training cost:  0.3851082985763138 \tValidation cost: 0.4049192409296428\n",
            "Epoch number : 16\n",
            "Training cost:  0.3787669131512871 \tValidation cost: 0.39944876878684876\n",
            "Epoch number : 18\n",
            "Training cost:  0.3738869638390689 \tValidation cost: 0.3951210672832837\n",
            "Epoch number : 20\n",
            "Training cost:  0.36895494313860694 \tValidation cost: 0.39164217956849884\n",
            "Epoch number : 22\n",
            "Training cost:  0.36504394163000076 \tValidation cost: 0.3884703643059706\n",
            "Epoch number : 24\n",
            "Training cost:  0.3613643439653589 \tValidation cost: 0.38587571035935636\n",
            "Epoch number : 26\n",
            "Training cost:  0.3587973887460075 \tValidation cost: 0.3835627836772484\n",
            "Epoch number : 28\n",
            "Training cost:  0.3577121962444791 \tValidation cost: 0.38316190691825264\n",
            "Epoch number : 30\n",
            "Training cost:  0.35459122474694593 \tValidation cost: 0.38030836750421537\n",
            "Epoch number : 32\n",
            "Training cost:  0.35339705179271846 \tValidation cost: 0.3798316632253777\n",
            "Epoch number : 34\n",
            "Training cost:  0.3518485257496139 \tValidation cost: 0.37904784184997375\n",
            "Epoch number : 36\n",
            "Training cost:  0.3490598280682777 \tValidation cost: 0.37652922262523647\n",
            "Epoch number : 38\n",
            "Training cost:  0.3472512298740818 \tValidation cost: 0.3751477782743699\n",
            "Epoch number : 40\n",
            "Training cost:  0.34601966218095137 \tValidation cost: 0.37413349599176365\n",
            "Epoch number : 42\n",
            "Training cost:  0.3448519587550453 \tValidation cost: 0.3735002008028394\n",
            "Epoch number : 44\n",
            "Training cost:  0.3452207705264584 \tValidation cost: 0.37371351011346604\n",
            "Epoch number : 46\n",
            "Training cost:  0.34408219958969505 \tValidation cost: 0.37305820532548556\n",
            "Epoch number : 48\n",
            "Training cost:  0.34399669389992227 \tValidation cost: 0.3725963756656141\n",
            "Epoch number : 50\n",
            "Training cost:  0.3437316339656647 \tValidation cost: 0.3726952143509446\n",
            "\n",
            "Final training cost: 0.3444032550410072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEcCAYAAACbAoDZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXwU9d3A8c83B0kgIZANBAXkUO4bwqFWDNUKKgWvWrWK1ApivX2q1eojFPXpoa3Wqn2KB3i1eLQPRcVSDyIeqIAiciqnBDwgHEkkB0m+zx+/2bBZNsnm2k3I9z2veWVn5jcz39md7HfnN7+ZEVXFGGOMaepioh2AMcYYEw5LWMYYY5oFS1jGGGOaBUtYxhhjmgVLWMYYY5oFS1jGGGOahUZLWCKiYfTb6rmOqd5yutdh3nn1XX9TVtP2ichQ7727tZoyd4tIuYj0CHOdR3weIrJNRObVN95q5hsqIrNEJC3ENBWRWbVdZn2ISJa33tMjud6mIODz3y8i7YOmxUXj8/DWPctbd1yk110bIhIjIg+KyFfe/92Caspuq+Z79cZIxh0UV3cvhisbY/mN+QGeGDT8f8CnwKyAccX1XMer3nq+qsO8dwN/quf6my1VXSUiq4HLgN8HTxcRAS4F3lHVrfVY1blAXj3mr8lQYCbwLLA3aNqJQE4jrtuElgr8Ergt2oE0MxcANwD/BSwDcmsov5jK36d+2xo0qiak0RKWqn4QOCwixcCe4PFBZWIBUdXSMNexG9hdx/g212W+o8xTwB9EZJiqfhI0bSzQHbinPisIsdyIqW5fM43qP8B1IvKAqn4T7WAiQUQSVLW+P8D7eX8fVNXyMMpX+316NIrqOSzv0PFeEblNRLYCJcAgEUkUkQdEZI2IFIjI1yLysoj0DZq/qiqoZ0XkIhFZLyLficgKEfle0LyVqqACDmWvEpHZ3mH5fm+9XYLmbS0ifxGRXC++/xORk7z5p9awzSeIyDMislVECkVki7es4CqUeSKSIyLDROQdETkoIl+IyIwQyzxNRD4WkSIR2SwiV9X03nueA0pxR1nBpgCFwIvhfh5VbO8RVYLhxisiv/bK5YnIHhF5S0TGBEyfCsz1Br8IqBLp7k0/ogpKRCaIyDLvvT8gIgtEpE9QmWwReVdETvfWf9Db9nNr2t5wiHOTiGwUkRJvX3tYRNoGlbvB24cLRWSftx+fGzB9vIi8721Hgbe8u6pZ70jvPZkUYtqjIrJbROK94UtE5BNvuXki8lkt9iv/j5w7a3gfZonIEbfaqeZ/c4aI/Mbb//K9//PW3v/UYi/WTSJyeRWr7CciS7zP8yvv/7zSd6CIdBCR/xWRnSJSLCIbRGR6UBn/985YEXlRRPYDH9awrdXud972zvIGyySM75JwyOHvw2nee1Pk7dPjQpS9VEQ+9crsEfc9dUyIctO8Zfj3y7dF5KSgYrFS8/do7fcxVY1IjztMfTZonAI7gXeA84EJQAauSuFx4CLgVFy10uvAPqBTwPxTvWV0D1rPdmA57hB7IvAJsB9oF1BuHrAtYLi7t6xtwN+AM4HLgT1AdlDcz+KqM28HfgD8FtjqzT+1hvdhLPA/wGTv9VTgc2BZULl5uKq09cBV3nr+5q1jXEC5fl4s7wHnAD/25tkRuH3VxPMKrko1NmBcInAAeM4bru/nMa8u8XrrvAwY532O8/F+1HjTO+CqdtX7rMd4fULA/jUrYHkTgDIv9knAJcAm3FF654By2d57shZXLTrBm6cUOKGG9zPLW+/p1ZT5H6/Mw8B44CagAPd/EOOV+Ym3vru87T8LV8X2M296T+99fM6L7/vefvK7GuLbALwQNK4Vrvrpz97w94By4EHgdOAM4HrglzUs2//5nwD8zouvmzctLsTnMQvQEMuZR+j/ze24WgH/e3YIeBr4zIvvB8A/vdgHBK8H2Azc4W3PH0LE0xbYCHwJTPO2/T5vn7kuxHbuwFWnnw5MqOZ9qXG/A4bhfnwph/fjDjV8nz7nva+V+hDlcnD/Yz/G/c8tA4qAPgHlpnvrnu/ta1cC3+K+m5IDyt3vlXsc+CFwNu5/8KLafI9S132spi+0huqpOmHtApJqmDcWaA3kAzeF2HGCvyD3Ae0DxmV65S4J458iO2jdv/DGH+sN9/He6FuDyj1EGAkrxLbFeR+eAsOC4gtOTgm4L5Y5AeOe83aGNgHjuuK+2LeFsf4fees5M2DcRd648Q30ecyrb7zeOuNwXyh/CrHOIxIJR34hrQC+IOCfGuiB++L7Y8C4bG9cr4BxHXFfOr+q4f3MopqEBaThvsjnBY2/1Jtvkjf8MPBxNeu5wCvftpb72x24I+fUgHHneMsaFbDP763NcoM/C2879wNPBuzn9U1YbwWV+6c3/tKAce1xiX5m8HqA24Lmf8zbh9t5w/+N+yLvFaLcHv9+E7CdD4T5voS7390T6v2oYpnbvBhC9ZlB5UqArgHjUnDne58J+N/6BlgStA7/99L13vAJ3v/AH6uJy/9ZZQeND/4erdM+1hSatf9bVQuDR4rIhSLyoXe4XQp8ByTjEkZNlqnqvoDhz7y/x4Ux76Kg4eB5RwMCvBhU7qUwlo2ItBKRX3lVDYW4nfYdb3Lwth1U1SX+AXV15J9TeTtOBBap6ncB5XbgjmDCsRCX4AOrBafgfki8ERB3fT6PQGHH61XJLRGRXG+dh4DedVgnItIGGA48rwHnSNU1KHkPd+QY6AtV/SKg3Le4X5zh7EPVGYM7onk2aPx83Db641gODBWRP3vvQ+ug8qtw78d8EblARDqGuf5ncT98fhQw7jJgo6p+FLDu9l5V0kQRaRfmsiuo6l7cUcwUCapyrYfXgoY3eH8XB6x3H+5z6hpi/heChufj9uGB3vAEXNXeVnGtGuPEtSxcDPiA/kHz/19NAddhv6uN14CRIfp1QeU+8P7H/OvO53CDNXD/Tx1xPyYJKPcu7qjWH+PpuNNIc8KIrabv0TrtY00hYR3Rwk9Efgg8jzuMvQSXJEbiDqETw1hmpdZievhkaK3n5XBLRv+8/jrdb4PKhXty+Te4X3zP4g6nRwHnVRHfPo5UHFTumCrWHVY83nvzPHCOiKSISAbu8PxZVS2DBvk8AoUVr4gMx+30BcDPcF/0I3EtTWu7TnC/vIXQLUq/xh0RBAreD+DI974u/OupFIf3ZZYbMP1p4Grce70Y2Csi/xTv/JyqbsJVjcUAzwBfi8gHIlLtF6CqbgeW4v1A8b4ozvaW4S/zNi6hdcV9Ke8WkTdEZHAtt/UB3Ps4u5bzVSX4/6GkmvGhPqfg/c4/3Nn72xFXTX8oqPf/OPUFzR9O6+Ta7ne1sVdVV4ToDwaVq+r/zb/dIffJEDH6tz+clrfVfo/WdR9rCtclaIhxFwGbVHWqf4R3Mrg+H25D8X+oHXHnrfwywpz/IuBpVa1ofSciyfWMJ9S6w40H3HmBGbhqpna4KoKnA6Y35OcRbrzn4444zlPVQwHrbY+raqqtfbh9rVOIaZ0InaAag389nXDnyAB3nRLuC2EvePVC8Ffgr942+8+7PI9LYnhH30tEJAE4GZcYXhWR7qq6p5oYngEeE5FuuKR3xBGfqr4EvOTtm1m4c1L/FpEuGl4LNlS1QER+48V9X4giRd62t1LVkoDxwYmhoWQAW4KGwZ1HB/eD4Vtc0/JQNgYNh/ruCtYU9ruq/t/82x24TwbrBKz0Xvv3qc4c+V7UWl32saZwhBVKa9yXVaDLcF+k0fYRbgf8UdD44OGqtMb9agv003rEsww4y6t6AEBEuuK+wMKirmns57j3eAqwUlXXBhRpyM8j3Hhb4+rLNaDc9zmySs7/yy2pupV6VZArgR+Ju3zCv8xuwEm481aR8AHuCOCioPE/xv2APCIOVd2nqs/jqrQGhpherKpv4RoAtMGdH6nOi7j37Se4z/Ed78jrCKpaoKqv4JLnMdQ+mTyK+2IMdXmEf50V2+Qd8QW3OGsoFwYNX4Q7gvdXV/0b6At8WcWRS35tV9hE9rsx3v+Yf90puKPqZd6ojbgjrkr7pNfyr1tAjG/gzt9XajVZX7XZx5rCEVYo/8ZVUT2Aa8WWCVxH3X5ZNyhV3SAifwPu9prErsS10PqhV6SmX5//Bi4Xkc9wLYXOo37/oPfgkuV/ROQ+3K/lWYRfRen3lLcswbXWCY65oT6PcOP9N3AjME9E5uLOXf03h38V+vnr668RkadwPwZWB/1i9/tvXN39KyLyKO78xa9xLSL/UIdtqc4pIerlS1V1gYj8AbhdRL7DVXv2w70v73rxISJzcA0CluF+9ffGJZf/eNNn4KqvFuFaq6XjWq3uAtZUF5iq5onIv4BrcF8Q0wKni8hs3C/wJd7yuuD2iVXqrn0Mm6oWe8sLdd7jNdx7/5iIzMSdW7sVl0QawzTvf3Y57sjySlwjkAPe9AdwPxze8fb1jbgfAH2BU1R1ch3X21j7XboEXOYR4GtV3RYw/A3u/20W7ofKL3HbdTeAqpaJuxziryLyLO5ouzNwL66xyJNeuc3e+3Kzl/QW4n5UjgI2eD+qwlLnfay2rTTq2lN1K8F7QpSNwf0D7wIOAm/jmn1uo3KLs6mEbpX2bIhlBrdQmkfolkhXBs2X5Y3PChjXGvgL7lC6wPvgzvbKTa7hfUjHnezd5/XP4c7NVGph6MWXE2L+bI5sgXM6rul+Ma7K46rg7Qvj8+mK2/lKgPQG/jzm1SVeXFLcimvVttybL9T2z8QlsrLA9Qd/5t64CbgkUIj7wvgXAc17A97jd6vYh+eFev9C7C+h+gKvjOCaZW/03u+vgEcIaPGHawqcjUtWxd778IC/DO6E+b9wyarYW8aLwdtSTZz+/bVSi8GAaYu9ZRZ763gCr4VXNcv0f/4nBI2Pwx3Bh/o8vud9tge9MpcG7wtU/b85yxsfqin3syHKDcR9QRbizs3cjXcZQUDZ9t77vNX7bL7FNYq6sabtrOG9CWe/a6hWgg8Hvxe45LzZ+zw/Ab4fYpmX4s4RF+OqR58BjglRbgaw2iu319tPT6zhs8oi4Hu0rvuYeDObehKRX+CqZLqr6pfRjscYY8RdkPyuql4a7VgaQlOtEmzSRGQi7tfaKlwV4Cm46wpesGRljDGNwxJW3eTjLra8DVcXvBN34fDMaAZljDFHM6sSNMYY0yw01WbtxhhjTCVHbZVgenq6du/evc7zf/fdd7Rp06bmgkcZ2+6Wxba7ZQlnu1euXLlHVTtEKKRaOWoTVvfu3VmxYkWd58/OziYrK6vhAmombLtbFtvuliWc7RaRkBeRNwVWJWiMMaZZsIRljDGmWbCEZYwxplk4as9hGWMi79ChQ+Tk5FBUVBTtUKqVmprK+vXrox1GxAVud2JiIl26dCE+Pj7KUYXPEpYxpsHk5OSQkpJC9+7dEZFoh1Ol/Px8UlJSoh1GxPm3W1XJzc0lJyeHHj1qurl/02FVgsaYBlNUVITP52vSycqAiODz+Zr8kXAwS1jGmAZlyap5aI6fkyWsIAc4wCxmsT6l5dVvG2NMU2YJK0gZZfyaX7M2dW3NhY0xTUpubi5Dhw5l6NChdOrUic6dO1cMl5SEeqbnYStWrOD664OfXXqkk05qmAciZ2dnM3HixAZZVksR0UYXIjIB+BPu0eqPq+pvg6Y/AIzzBlsDHVW1nTftcuBOb9o9qvpUY8TYjnbEEENeXF5jLN4Y04h8Ph+rVq0CYNasWSQnJ/OLX/yiYnppaSlxcaG/9jIzM8nMzKxxHe+//37DBGtqLWJHWCISi3uq6plAf+BiEekfWEZVb1LVoao6FPgz8E9v3jTcoztG4x7HPFNE2jdGnDHE0J72HIg/UHNhY0yTN3XqVGbMmMHo0aO59dZb+eijjzjttNMYNmwYJ510Ehs3bgQqH/HMmjWLK664gqysLHr27MlDDz1Usbzk5OSK8llZWVxwwQX07duXn/zkJ/6n67Jo0SL69u3LiBEjuP7662s8ktq7dy/nnHMOgwcPZsyYMaxevRqAt99+u+IIcdiwYeTn5/PVV18xduxYhg4dysCBA3nnnXca/D1rqiJ5hDUK2KSqWwBEZD4wGVhXRfmLOfx8qfHA66q615v3ddwjp//eGIH68JEXb0dYxtTLjTeCd7TTYIYOhQcfrPVsOTk5vP/++8TGxpKXl8fixYtp3749b7zxBr/61a/4xz/+ccQ8GzZsYMmSJeTn59OnTx+uvvrqI65Z+uSTT1i7di3HHnssJ598Mu+99x6ZmZlcddVVLF26lB49enDxxRfXGN/MmTMZNmwYCxYs4K233mLKlCmsWrWK+++/n0ceeYSTTz6ZgoICEhMTmTNnDuPHj+eOO+6grKyMgwcP1vr9aK4imbA6AzsChnNwR0xHEJFuQA/grWrm7RxivunAdICMjAyys7PrFGj8sHj2yb46z9+cFRQU2Ha3IA293ampqeTn5wOQUFJCTFlZgy0boLykhGJv+TUpLi4mPj6eQ4cOMXHixIov9p07d3LLLbewZcsWRIRDhw6Rn5/PwYMHKS0tJT8/n+LiYk4//XRKSkpISEggPT2dzZs307mz+9rxlx8xYgSpqal89913DBgwgPXr1yMidOvWjfT0dPLz8znnnHOYO3duxfviF7i+pUuX8swzz5Cfn8/IkSPZs2cPO3fuJDMzkxtuuIELL7yQSZMm0blzZwYMGMDPf/5zCgoKmDhxIoMHDz5i2VUpKyurVLaoqKhZ7fdN9cLhi4CXVLVWe7uqzgHmAGRmZmpd78bcgx5syN9gd3NuQWy7G8b69esPX5D76KMNttxArcIsl5CQQEJCAvHx8aSnp1fE9bvf/Y6xY8fyyiuvsG3bNrKyskhJSaF169bExcWRkpJCQkICycnJFfPEx8eTmJhYMewv37p164pxiYmJxMfH06ZNG2JjYyvGJyUlVSw3UOD6YmJiKq1PREhJSWHmzJmcd955LFq0iPHjx7N48WImTJjAu+++y6uvvso111zDzTffzJQpU8J6T4IvmE5MTGTYsGFhvqPRF8lWgjuBrgHDXbxxoVxE5eq+2sxbb1YlaMzR68CBAxx77LEAzJs3r8GX36dPH7Zs2cK2bdsAeP7552uc55RTTuG5554D3I+I9PR02rZty+bNmxk0aBC//OUvGTlyJBs2bGD79u1kZGQwbdo0rrzySj7++OMG34amKpIJaznQS0R6iEgrXFJaGFxIRPoC7YFlAaMXA2eISHuvscUZ3rhGYQnLmKPXrbfeyqxZsxg2bBilpaUNvvykpCQeffRRJkyYwIgRI0hJSSE1NbXaeWbNmsXKlSsZPHgwt912G0895RpBP/jggwwcOJDBgwcTHx/PmWeeSXZ2NkOGDGHYsGE8//zz3HDDDQ2+DU2WqkasB84CPgc2A3d442YDkwLKzAJ+G2LeK4BNXv/TmtY1YsQIrat79V5F0UItrPMymqslS5ZEO4SosO1uGOvWrWvQ5TWWvLy8Rl1+fn6+qqqWl5fr1VdfrX/84x8bdX3hCt7uUJ8XsEIjmBdq00f0HJaqLgIWBY27K2h4VhXzPgk82WjBHV4RvoOJ0AZyyaXzkW07jDGmWo899hhPPfUUJSUlDBs2jKuuuiraIR0Vmmqji+j56it81/8XvGQJyxhTNzfddBM33XRTtMM46titmYL5fPhy3ctccqMbizHGmAqWsIIlJOArTAIsYRljTFNiCSsEn6YBlrCMMaYpsYQVQlpsB8ASljHGNCWWsEJISu5AUqFYwjKmmRk3bhyLF1e+RPPBBx/k6quvrnKerKwsVqxYAcBZZ53F/v37jygza9Ys7r///mrXvWDBAtatO3xr1Lvuuos33nijNuGHZI8hOcwSVig+H2n7YtjL3mhHYoyphYsvvpj58+dXGjd//vywbkAL7i7r7dq1q9O6gxPW7NmzOf300+u0LBOaJaxQ0tPx7VE7wjKmmbngggt49dVXKx7WuG3bNnbt2sUpp5zC1VdfTWZmJgMGDODee+8NOX/37t3Zs2cPAPfeey+9e/fme9/7XsUjSMBdYzVy5EiGDBnC+eefz8GDB3n//fdZuHAht9xyC0OHDmXz5s1MnTqVl156CYA333yTYcOGMWjQIK644gqKi4sr1jdz5kyGDx/OoEGD2LBhQ7Xb19IfQ2LXYYXi85G+u5xc3QMS7WCMaZ5u5EZW0bCPFxnKUB6k6seLpKWlMWrUKF577TUmT57M/PnzufDCCxER7r33XtLS0igrKyMrK4vVq1czePDgkMtZuXIl8+fPZ9WqVZSWljJ8+HBGjBgBwHnnnce0adMAuPPOO3niiSe47rrrmDRpEhMnTuSCCy6otKyioiKmTp3Km2++Se/evZkyZQp/+ctfuPHGGwFIT0/n448/5tFHH+X+++/n8ccfr3L7WvpjSOwIKxTvWqzcst3RjsQYU0uB1YKB1YEvvPACw4cPZ9iwYaxfv75S9V2wd955h3PPPZfWrVvTtm1bJk2aVDFtzZo1nHLKKQwaNIjnnnuOtWvXVhvPxo0b6dGjB7179wbg8ssvZ+nSpRXTzzvvPABGjBhRccPcqrz77rtcdtllAHz/+98nNzeXvLw8Tj75ZG6++WYeeugh9u/fT1xcHCNHjmTu3LnMmjWLzz777Ii7xTdHdoQVij9hWZWgMXVW3ZFQY5o8eTI33XQTH3/8ccUzq7Zu3cr999/P8uXLad++PT/5yU8oKiqq0/KnTp3KggULGDJkCPPmzav386QSEhIAiI2NrfPNeG+77TbOPvtsFi1axMknn8zixYsZO3YsS5cu5dVXX2Xq1KncfPPNnHvuufWKNdrsCCuU9HR8ubA39gDllEc7GmNMLSQnJzNu3DiuuOKKiqOrvLw82rRpQ2pqKt988w2vv/56tcsYO3YsCxYsoLCwkPz8fF5++eWKafn5+RxzzDEcOnSo4pEg4J6RFepBin369GHbtm1s2rQJgGeeeYZTTz21TtvW0h9DYkdYoXhHWOVSzgEO0J720Y7IGFMLF198Meeee25F1aD/cRx9+/ala9eujBkzptr5hw8fzo9//GOGDBlCx44dGTlyZMW0u+++m9GjR9OhQwdGjx5dkaQuuugipk2bxkMPPVTR2ALcQxLnzp3Lj370I0pLSxk5ciQzZsyo03bNmjWLK664gsGDB9O6detKjyFZsmQJMTExDBgwgDPPPJP58+dz3333ER8fT3JyMk8//XSd1tmUiLub/NEnMzNT/ddW1Nq2bTx9Vw8ufxq+4AtO4ISGDa4JsyfvtiyN8cThfv36NdjyGkvwk3dbiuDtDvV5ichKVc2MdGzhsCrBUOwGuMYY0+RYwgolOZn2B2IBS1jGGNNUWMIKRYTUEnfYbAnLmNo5Wk8zHG2a4+dkCasKKYfaApawjKmNxMREcnNzm+WXYUuiquTm5pKYmBjtUGoloq0ERWQC8CcgFnhcVX8bosyFwCxAgU9V9RJvfBnwmVfsS1WdFDxvQ0qmHTFlX5IbawnLmHB16dKFnJwcdu9u2hfdFxUVNbsv64YQuN2JiYl06dIlyhHVTsQSlojEAo8APwBygOUislBV1wWU6QXcDpysqvtEpGPAIgpVdWik4i1LSaV9Xiy57S1hGROu+Ph4evToEe0wapSdnc2wYcOiHUbENfftjmSV4Chgk6puUdUSYD4wOajMNOARVd0HoKrfRjC+Sg6lptrdLowxpgmJZJVgZ2BHwHAOMDqoTG8AEXkPV204S1X/7U1LFJEVQCnwW1VdELwCEZkOTAfIyMio1y1TOicl4dtdxqa0TWSvrvtympuCgoJ632qmObLtbllsu5unpnanizigF5AFdAGWisggVd0PdFPVnSLSE3hLRD5T1c2BM6vqHGAOuAuH63NB5KYXXsC3B3JGHWpRF5TaBbQti213y9LctzuSVYI7ga4Bw128cYFygIWqekhVtwKf4xIYqrrT+7sFyAYatSK2tG1bVyWoexpzNcYYY8IUyYS1HOglIj1EpBVwEbAwqMwC3NEVIpKOqyLcIiLtRSQhYPzJQNXPBmgAh/wJS/Y15mqMMcaEKWIJS1VLgWuBxcB64AVVXSsis0XE30R9MZArIuuAJcAtqpoL9ANWiMin3vjfBrYubAz+RhcHY4soom6PITDGGNNwInoOS1UXAYuCxt0V8FqBm70+sMz7wKBIxOh3qG1bfO7p0+SSS2c6R3L1xhhjgtidLqrgrxIEa9pujDFNgSWsKpQmJ+Pb615bwjLGmOizhFWV2Fh8pamAJSxjjGkKLGFVw6dpgCUsY4xpCixhVSMttgNgCcsYY5oCS1jVSErpSFKhWMIyxpgmwBJWdXw+fPtiLGEZY0wTYAmrOunp+PaUs5e90Y7EGGNaPEtY1fH58O1Wcsua9sPojDGmJbCEVR2fz91PsNwSljHGRJslrOr4E5ZYlaAxxkSbJazqpKfjy4W9sQcopzza0RhjTItmCas63hFWuZRzgAPRjsYYY1o0S1jV8RIW2MXDxhgTbZawqmMJyxhjmgxLWNVp1QpfYRJgCcsYY6LNElYN7Aa4xhjTNFjCqoFP0gFLWMYYE20RTVgiMkFENorIJhG5rYoyF4rIOhFZKyJ/Cxh/uYh84fWXRyrmdq06ElNmCcsYY6ItLlIrEpFY4BHgB0AOsFxEFqrquoAyvYDbgZNVdZ+IdPTGpwEzgUxAgZXevPsaO+6YtHTaH4ghN80SljHGRFMkj7BGAZtUdYuqlgDzgclBZaYBj/gTkap+640fD7yuqnu9aa8DEyIStXfxsB1hGWNMdEXsCAvoDOwIGM4BRgeV6Q0gIu8BscAsVf13FfN2Dl6BiEwHpgNkZGSQnZ1d52ALCgrIzs6mW34+vt3lbPJ9Qfbqui+vufBvd0tj292y2HY3T5FMWOGIA3oBWUAXYKmIDAp3ZlWdA8wByMzM1KysrDoHkp2dTVZWFqxZgy93Hjkph6jP8pqLiu1uYWy7Wxbb7uYpklWCO4GuAcNdvHGBcoCFqnpIVbcCn+MSWDjzNg7/DXDZE5HVGWOMCS2SCWs50EtEeohIK+AiYGFQmQW4oytEJB1XRbgFWAycISLtRaQ9cIY3rvH5E1bM/oiszhhjTGgRq4sW3kEAACAASURBVBJU1VIRuRaXaGKBJ1V1rYjMBlao6kIOJ6Z1QBlwi6rmAojI3bikBzBbVSPzzA+v0cXB2CKKKCKRxIis1hhjTGURPYelqouARUHj7gp4rcDNXh8875PAk40d4xGC7ifY+ci2HsYYYyLA7nRRE7sBrjHGNAmWsGrSpg2+PHcgagnLGGOixxJWTUTwlbcHLGEZY0w0WcIKgw8fYAnLGGOiyRJWGNJiOwCWsIwxJposYYUhKaUjSYViCcsYY6LIElY40tPx7bWEZYwx0WQJKxw+H77d5eyN0LXKxhhjjmQJKxz+2zOVfRPtSIwxpsWyhBUOf8IqtxvgGmNMtFjCCoc/YYlVCRpjTLRYwgqHdwPcvXF5lFMe7WiMMaZFsoQVDu8Iq1zKOcCBaEdjjDEtkiWscNgNcI0xJuosYYWjXTt8+wSwhGWMMdFiCSscMTH4DrUFLGEZY0y0WMIKk0/TAEtYxhgTLZawwuSTdMASljHGREtEE5aITBCRjSKySURuCzF9qojsFpFVXn9lwLSygPELIxk3QLuEDGLKLGEZY0y0xEVqRSISCzwC/ADIAZaLyEJVXRdU9HlVvTbEIgpVdWhjx1mVmLR02h+IITfNEpYxxkRDJI+wRgGbVHWLqpYA84HJEVx//aSn0/VLZROboh2JMca0SJFMWJ2BHQHDOd64YOeLyGoReUlEugaMTxSRFSLygYic06iRhuLzMepD5SP9yO52YYwxURCxKsEwvQz8XVWLReQq4Cng+960bqq6U0R6Am+JyGequjlwZhGZDkwHyMjIIDs7u86BFBQUVJr/mD17GP05zLnqAM9+9CzHHTyuzstuyoK3u6Ww7W5ZbLubp3onLBGJV9VDYRTdCQQeMXXxxlVQ1cATRI8Dvw+YttP7u0VEsoFhwOag+ecAcwAyMzM1Kysr7O0Ilp2dTaX59+6l9L//4NYzSsmi7stuyo7Y7hbCtrtlse1unmpVJSgi14vI+QHDTwCFXsu/PjXMvhzoJSI9RKQVcBFQqbWfiBwTMDgJWO+Nby8iCd7rdOBkILixRuNKT6fvBkguTeJDPozoqo0xxtT+HNb1wG4AERkLXAhcAqwC/lDdjKpaClwLLMYlohdUda2IzBaRSf7li8haEfnUW9dUb3w/YIU3fgnw2xCtCxuXz0dsOYzM7WkJyxhjoqC2VYKdga3e6x8CL6rqCyLyGfBOTTOr6iJgUdC4uwJe3w7cHmK+94FBtYy1Yfl8AIze2Zn7M96ikEKSSIpqSMYY05LU9ggrD+jovf4B8Kb3+hCQ2FBBNUlp7tZMozf5KKWUj/k4ygEZY0zLUtuE9R/gMRF5HDgBeM0bP4DDR15Hp1atICWF0WvaAPARH0U5IGOMaVlqm7CuAd4DOgAXqKr/mfHDgb83ZGBNUqdOHLN2L13pauexjDEmwmp1DktV84DrQoyf2WARNWUjRsC77zKaMZawjDEmwmrbrL1/YPN1EfmBiDwrIrd79wo8up14IuTkMHp/H7axjW/5NtoRGWNMi1HbKsEncRfs4t026V9AGq6q8J6GDa0JGjMGgNGrEgDsKMsYYyKotgmrL1Q0j7sA+FBVzwIuAy5uyMCapKFDISGBEYv3EEusJSxjjImg2iasWKDEe30ah6+p2gxkNFRQTVarVjBiBK2XrmAQgyxhGWNMBNU2Ya0BrhaRU3AJ69/e+M7AnoYMrMk68URYuZLRZZl8hN253RhjIqW2CeuXwDQgG3dX9c+88ZOghVyYNGYMFBczensn8shjIxujHZExxrQItW3WvlREOgBtVXVfwKS/AgcbNLKm6sQTARj9fhn0dA0v+tEvykEZY8zRr9YPcFTVMtwd2geKyAARSVTVbaraMtp4d+4MXbrQd9EW2tLWzmMZY0yE1PY6rDgRuQ/YB3wKfAbsE5Hfi0h8YwTYJJ14IjHLPmQkI+0WTcYYEyG1PcL6PXApMAPoDfQCrsY1a/9Nw4bWhI0ZA9u2MbpgAKtZTSGF0Y7IGGOOerVNWJcAP1PVp1R1s9fPA64EftLg0TVV/vNYa9rYnduNMSZCapuwUgl6LL1nM9Cu/uE0E8OGQXw8o1/PA+yOF8YYEwm1TVj+JwEHu8Gb1jIkJsKwYWS88Rnd6GYJyxhjIqC2Txy+FVgkIqcDH3jjxgDHAmc2ZGBN3oknwpw5jC4/mw9jLGEZY0xjq9URlqouxTW2eAlI9voXgfGEPvI6eo0ZA4WFjN7Vle1s5xu+iXZExhhzVKvLdVi7VPUOVT3f6+8EvgPOr2leEZkgIhtFZJOI3BZi+lQR2S0iq7z+yoBpl4vIF15/eW3jbnD+hhcfCWDnsYwxprHVOmHVlfe8rEdwVYf9gYtFpH+Ios+r6lCvf9ybNw2YCYwGRgEzRaR9hEIP7bjjoFMnhr+yizjiLGEZY0wji1jCwiWaTaq6RVVLgPnA5DDnHQ+8rqp7vVtCvQ5MaKQ4wyMCJ55I0jsrGMxgPqg4pWeMMaYx1LbRRX10BnYEDOfgjpiCnS8iY4HPgZtUdUcV83YOnlFEpgPTATIyMsjOzq5zsAUFBTXO37VDB47ftIm+n5/L8ycs5MUPXqRDSYc6r7MpCGe7j0a23S2LbXfzFFbCEpGFNRRp2wCxALyMuwt8sYhcBTwFfD/cmVV1DjAHIDMzU7OysuocSHZ2NjXOHxsLc+Zwd85Z/L33AtactIZf8+s6r7MpCGu7j0K23S2LbXfzFG6VYG4N/Vbg6RqWsRPoGjDcxRtXQVVzVbXYG3wcGBHuvFExYgTExdHzza2czdn8lb9SUvF8S2OMMQ0prCMsVf1pA6xrOdBLRHrgks1FuFs9VRCRY1T1K29wErDee70Y+J+AhhZnALc3QEz107o1DBkCH3zAdfyS8YznJV7iksqbZYwxpgFErNGFqpYC1+KSz3rgBVVdKyKzRWSSV+x6EVkrIv47akz15t0L3I1LesuB2d646BszBj76iNPLxtGb3vyZP0c7ImOMOSpFspUgqrpIVXur6vGqeq837i5VXei9vl1VB6jqEFUdp6obAuZ9UlVP8Pq5kYy7WieeCAUFxKxdzzVcwwd8wApWRDsqY4w56kQ0YR2Vxoxxf5ctYypTSSaZh3k4ujEZY8xRyBJWffXsCR06wAcf0Ja2TGEK85nPbnZHOzJjjDmqWMKqL+8CYt56C8rKuJZrKaaYJ3gi2pEZY8xRxRJWQ7jsMvjyS3j1VfrRj9M4jUd5lFJKox2ZMcYcNSxhNYRzzoEuXeChhwC4juvYwQ5e5uUoB2aMMUcPS1gNIS4OrrkG3nwT1q5lIhM5juOsibsxxjQgS1gN5cor3ZOI//xnYonl5/ycJSxhLWujHZkxxhwVLGE1lPR0+MlP4OmnYe9eruRKEkm0Ju7GGNNALGE1pOuvh8JCeOIJfPi4mIt5mqfZ2QRue2iMMc2dJayGNHgwZGXBww9DaSl3cAeKchVXoWi0ozPGmGbNElZDu/5618T95Zc5nuO5l3t5lVd5lmejHZkxxjRrlrAa2g9/CN26VTRxv57rOYmTuIEb+IqvapjZGGNMVSxhNTR/E/fsbFi9mlhieZInKaSQq7naqgaNMaaOLGE1hp/9DJKSKo6y+tCH2czmX/yL+cyPcnDGGNM8WcJqDGlp7nZNzz0He/YAcDM3M4pRXMd1fMM3UQ7QGGOaH0tYjeX666GoCB5/HIBYYpnLXPLJ51qujXJwxhjT/FjCaiwDBsBpp8Ejj7jEBfSnPzOZyUu8xIu8GOUAjTGmebGE1Zhuvx1ycmDmzIpRt3IrIxjBNVzDLnZFMThjjGleIpqwRGSCiGwUkU0icls15c4XERWRTG+4u4gUisgqr//fyEVdD6edBtOmwf33w7JlAMQRx1zmcpCDjGOc3QXDGGPCFLGEJSKxwCPAmUB/4GIR6R+iXApwA/Bh0KTNqjrU62c0esAN5f773aNHpk51t20CBjGIxSzmK77iVE5lBzuiG6MxxjQDkTzCGgVsUtUtqloCzAcmhyh3N/A7oCiCsTWetm3hiSfg88/hzjsrRp/MyfyH/7Cb3ZzKqWxnexSDNMaYpi8uguvqDJUOJXKA0YEFRGQ40FVVXxWRW4Lm7yEinwB5wJ2q+k7wCkRkOjAdICMjg+zs7DoHW1BQUK/5K4mLo9ekSRz7wAOs6t6dA4MGVUz6XcrvuGXwLYwuG80Dqx7gmKJjGmadddSg292M2Ha3LLbdzZSqRqQHLgAeDxi+DHg4YDgGyAa6e8PZQKb3OgHwea9H4BJf2+rWN2LECK2PJUuW1Gv+I+Tnq3bvrnrCCarffVdp0kpdqe21vXbVrvqFftGw662lBt/uZsK2u2Wx7a4asEIjlBdq20eySnAn0DVguIs3zi8FGAhki8g2YAywUEQyVbVYVXMBVHUlsBnoHZGoG0pyMsydC5s2wa9+VWnScIazhCUc5CCnciob2BClII0xpumKZMJaDvQSkR4i0gq4CFjon6iqB1Q1XVW7q2p34ANgkqquEJEOXqMNRKQn0AvYEsHYG0ZWFlx7LfzpT/D225UmDWEIS1hCKaWcxEksZWl0YjTGmCYqYglLVUuBa4HFwHrgBVVdKyKzRWRSDbOPBVaLyCrgJWCGqu5t3IgbyW9/Cz17wk9/Cnl5lSYNYhDLWEYGGfyAH/Acz0UpSGOMaXoi2egCVV0ELAoad1cVZbMCXv8D+EejBhcpbdrAvHkwbhyceSb8+9+QklIxuSc9eZ/3OY/zuJRL2cIW7uROBIlezMYY0wTYnS6i4ZRT4Pnn4cMPYcKEI4602tOexSzmMi7jLu7ip/yUEkqiFKwxxjQNlrCi5fzzXdL66KOQSasVrXiKp5jFLJ7iKSYwgf3sj1KwxhgTfZawosmftJYvD5m0BGEmM3mKp3iXdxnMYF7l1SgFa4wx0WUJK9rOO6/apAUwhSksZSkppDCRiVzIhXzFV1EI1hhjoscSVlNw3nnwwgsuaY0fDwcOHFFkDGP4hE+4h3tYyEL60Y85zKGc8igEbIwxkWcJq6k491yXtFasgFNPhV1HPnqkFa24gztYzWqGM5yruIqxjGUd66IQsDHGRJYlrKbk3HPhlVfc3TBOPBHWrw9ZrDe9eZM3mctc1rOeIQzhRm5kL83z0jRjjAmHJaymZvx4WLoUiovh5JPh3XdDFhOEqUxlAxv4GT/jz/yZXvTiER6hlNIIB22MMY3PElZTNHy4e+Bjx45w+unwj6qvme5AB/6X/+UTPmEIQ7iWaxnCEBazOIIBG2NM47OE1VT16AHvvQcjRsCPfgQPPVRt8cEM5k3eZAELKKaYCUzgTM7kTd5E0QgFbYwxjccSVlPm88Ebb8A558ANN8A118DBg1UWF4TJTGYta7mP+1jOck7ndPrRjz/xJ7vw2BjTrFnCauqSkuDFF+G//gsefdRVF374YbWzJJDAL/gFOeTwNE/TnvbcyI10pjPTmMYnfBKh4I0xpuFYwmoOYmPh/vvd0dbBg3DSSXDnnVBS/f0FE0nkMi5jGctYyUou4RKe4zmGM5wBDGAmM1nDGqsyNMY0C5awmpPTToPPPoMpU+Dee2H0aDcchuEM5zEeYxe7eIRH6EhH7uEeBjGIfvTjTu5kFasseRljmixLWM1Naqp7cvG//uUuLs7MdM/YOnQorNnb0Y6f83OWsIRd7OIv/IUudOE3/IZhDOPyUZczm9l8wReNvCHGGFM7lrCaq0mTYO1a9/f2211rwmXLarWIDDKYwQze4A2+5mv+yl/xFfuYxSx605tRjOJP/MnuW2iMaRIsYTVn6emuQcaCBbBvn7vQeMYM97qWOtCB6UzngU8f4Eu+5D7uo5RSbuRGutCFsYzlXu7lIz6ijLJG2BhjjKmeJayjweTJsG4d3HgjPPYY9O0Lf/87aN3OR3WhC7/gF3zMx6xjHXdwBwUUcCd3MprRdKADP+JHPMZjbGNbw26LMcZUIaIJS0QmiMhGEdkkIrdVU+58EVERyQwYd7s330YRGR+ZiJuRlBT44x/dHd+POw4uuQTOOMM9ILIe+tGP2czmYz7mG77hb/yNyUxmGcuYznR60IPudGcqU5nLXLay1RpuGGMaRcQSlojEAo8AZwL9gYtFpH+IcinADcCHAeP6AxcBA4AJwKPe8kyw4cPhgw/gz3+GlStdS8Lx46u8J2FtdKQjF3Mxc5nLDnawlrU8xENkksmrvMoVXEFPetKd7kxhCnOYw1rW2iNQjDENIpJHWKOATaq6RVVLgPnA5BDl7gZ+BxQFjJsMzFfVYlXdCmzylmdCiY2Fa6+F7dvhd7+DVavglFMgKwvefLPOVYWBBKE//bmO63iJl/iGb1jDGh7mYUYxisUs5iquYiADSSediUzkN/yGpSylgIL6b6MxpsURbYAvr7BWJHIBMEFVr/SGLwNGq+q1AWWGA3eo6vkikg38QlVXiMjDwAeq+qxX7gngNVV9KWgd04HpABkZGSPmz59f53gLCgpITk6u8/xNSUxREce88grHPf88CXv2cGDAAHaedx67v/c9tFWrSmUbarsVZVfSLj5L/Yw1bdewJnUN29tsd/FoDF0PdqV3fm965/emT0EfTig4gaSypHqvt66Ops+7Nmy7W5ZwtnvcuHErVTWz2kJREhftAPxEJAb4IzC1rstQ1TnAHIDMzEzNysqqczzZ2dnUZ/4mZ8IEd7eMefNI/f3vSb37btfKcOpUmDYNevcGGne7c8llGctYIStY2WYlK9us5PVOrwMQQwy96MXgoK4b3RCkUeIJdNR93mGy7W5Zmvt2RzJh7QS6Bgx38cb5pQADgWwRAegELBSRSWHMa8KRmOiavU+f7m7zNGcOPPigS2RZWTB9OuLzNdrqffiY6HV+u9jFSq9bzWo+5mNe5MWK6W1pyyAGMYQhDGUoQxjCQAbSmtaNFqcxpmmKZMJaDvQSkR64ZHMRcIl/oqoeANL9w0FVgoXA30Tkj8CxQC+gfs3fWrKYGNeC8Iwz4Ouv3Z0zHnsMLrmEE9u1g6uucn2PHo0eyrFe90N+WDEun3zWspbVrOZTPmU1q3mGZ3iUR134xNCb3gxkIN3pTje6cRzH0c3r2tGu0eM2xkRexBKWqpaKyLXAYiAWeFJV14rIbGCFqi6sZt61IvICsA4oBa5RVbt6tSF06uTulPHLX8Ibb3Dg7rvpcN998Pvfu2rEq6+Gs85yDTkiJIUUxnidXznlbGMbn/Ipq1jFp173Mi9TTHGl+VNJpS99GcAA+nvdAAbQla4RqV40xjSOiJ7DUtVFwKKgcXdVUTYraPhe4N5GC66l84661rZqRdYJJ7gjrscec7d+Ou44+NnP4NJLoWfP6IRHDD297lzOrRivKN/yLdvZzpd8yXa2s5WtrGc9r/IqT/JkRdlkkulOd7rQha5B3deJX3OIQ8QTH43NM8aEock0ujBNSJcu8Otfu0eYvPwy/OUvMGsWzJzpHm1y2WVw4YWQlhbtSBGEDK8bFeJKh1xyWRfQbWc7O9jBx3zMt3x7uOAYuJzLOY7jOD6g60Y3OtGJDDLoRCfa0taO0oyJEktYpmrx8XDeea7fsQOeew6eecZVE15/PZx9trujxoQJ7k4bTZAPH6d4XbAiitjJTnawg9c2vEZ833g2e92LvMhe9h4xTwIJFcmrE504xusCX3emMxlkEItd225MQ7KEZcLTtSvcdps717VqlUtcf/ubu/Fuq1YwbpyrPvzhD13ZZiCRxIojKb6GrL5ZlabvZz872ME3fMPXfH3E361s5X3eZw97jlh2LLF0ohNd6EJnr0sgAUUpp7zS33jiaU1r2tCG1l7XhjakklrRKCWddGLs1p+mhbOEZWpHBIYNc/3vfw/vveeqDRcuhGuucf3QoTBxonvg5Jgxrjl9M9TO6wYxqNpyhzhUkcR2eV0OOexkJznksJ71vMmblFBCDDEIUvFXEA5xiIMcrPYejPHEVxy9daYzvehF74DOh8+qKs1RzxKWqbu4ODj1VNfffz9s3OgS18svw//8D9xzj0tWJ57ojsDGjYNRo9wR2VEknni6eF1dKUoRRRzkIN/xHQc5yF728hVfsYtd7GRnRTL8lE9ZwAJKKa2Yvx3t6E1venhd94CuG90oo4xvvW43uyv+bjpuE5/zOWmk4cNHmte1pS0a0PljjCeetrSt93tmTF1YwjINp08fuOUW1+/fD++8A0uWuH7mTLjrLmjd2iUwf6IbPRoSEqIdedQJQpLX+aj54u1DHGI72/nc677gCz7nc1aykn/yTw4R3hOo6QmP83itYu1ABwZ4nf+SgX70s2pL0+gsYZnG0a6dO5/1Q++C4L17YelSl7zeftslMFWXrMaMOZy8Bg+Gzp1d1aOpUjzxnOB1Z3FWpWlllFWcY9vGNraznXji6UAHOtKx0t93l77LwLEDySWXvV6XSy755FdUWfo7cA1VNrKRdazjGZ4hj7xK604hhbZBXRe60Deg60lP4uyrx9SB7TUmMtLS4JxzXA8ugb3zjkteb7/tqg/Lyw+XHTLEJa8hQ2DkSBgwwJJYmGKJrTjX9T2+V23ZhPKEirK1pSg72ck61rGe9exlL3lB3QEO8BqvMZe5FfP5k20HOlAY0BVRRCGFlFJKK1qRSCIJXpfodW1pSzvakep1/vOM6aRXXN6QQQappIY8p+eves2Py+crvqKYYooCukMcIoYYYoO6GGIq4guOOYWUilajnehEMtG7qa6ifMd3FFJIBzpELY7GYgnLREdamntS8mTvCTN5efDpp7B69eG/jz0GBw+66R06wPe/f7g//nhLYFEmSMW5uzM4o9qy+9nPRjayIaDbxz58+EgksaI6NIkk4oijhJKKZOL/W0ghe9jDZjazn/0c4AAllIRcXwIJdKQj8cRXSoZF/qcWVZ/H66U1relEJ1JJrZR0/V0rWhFHXEUy9L8WhGKKj4i3iCLiiKMVrSrm93ff8R172EOu1+1hDyWUcBIn8R7vNd5GRoklLNM0tG3rntl1SsD1UmVlsHkzvP8+vPWWe5bX88+7accdB2PHuqOwQYNg4ECrSmzC2tGO0V7XkIooYh/72M1uvgnRlVJaKRn6u5xNOQw6YVBFQvEfwcUTTznllFJKWUBXTvkRiTWJJBJJ5AAHKlqJBnZ55FHsdfvYV/G6hBLKKKu0jlJKUbQiDv+yk0gigQTKKKtI0P6umGLa0AYfPo7neEYxCp/XHc/xDfo+NxWWsEzTFRvrHnvSu7d7DIoqfPHF4eT11lvw7LOHy7dr5xKXP4ENHuz+trOb4R6tEkmsuGC7NrJzssk6IatxgjKNxhKWaT5EDiewGTPcuL17Yc0a+Oyzw3+fe85VMfp17eqSmD+R9e8P/fpBUvQeGGmMqT1LWKZ5S0tzVYNjxx4ep+puJfXZZ4f7NWvg9dfhkNfcW8TdyHfAAOjfn45xcZCR4ZJhBO9Mb4wJnyUsc/QRcee4jjvO3e/Q79Ah2LQJ1q6t3C9aRP/SUtdSMSnJHYkNHer6gQNdA49jjrHzY8ZEmSUs03LEx7uqwH794IILDo8vKWH5M88wMj7e3Sfxk0/ghRfcE5n9kpLcAy2PP971PXq4qsYuXVzfsaMdmRnTyCxhGdOqFd8dfzxkZcGUKW6cKmzfDhs2uJaKW7Yc/vvmm4eb2/vFxcGxx7rk1bWrO7oL/Nu1K7Rp45Kav7cjNmNqxRKWMaGIQPfurg+mCrt3w86dkJPjzpfl5Bx+vWIF/N//QUnoa4QqrSMuDpKT3RFahw6u97/u1OlwsuvaFXw+S3KmRbOEZUxtibik0rGju2t9KOXlLqnt2AFffumSWWGhu7YsuM/Ph2+/deU//9zdAX/PnsN3/vBLSnJHcN26Qd++rvdXcXbqZMnMHPUimrBEZALwJyAWeFxVfxs0fQZwDVAGFADTVXWdiHQH1gMbvaIfqOqMSMVtTK3FxLhWhxkZkJlZ+/nLyg4nPH/S87/euhWeesolOr/UVJe4+vd3/YABru/SJXQiKy2FvDxiCwvrvo3GRFjEEpaIxAKPAD8AcoDlIrJQVdcFFPubqv6vV34S8Edggjdts6oOjVS8xkRVbKw7aurUyd1LMZgq7NoF69e7fsMGWLcOXnkFnnzycLmUFJfI4uPdHfQPHHB/CwoA3HOY09Jc1We3bq7v3t2tNy7OxeH/GxvrjvL69HFHl8ZEWCSPsEYBm1R1C4CIzAcmAxUJS1UDb/3cBqp5op0xLZmIuxVV585w+umVp+3Z45LXunWu2f769W58nz7urh+pqRV/N69bx/GxsbBtm3ue2eLFRzYoCSU93TX5Hzjw8NHcsce682ypqVY9aRpFJBNWZ2BHwHAOHHljMRG5BrgZaAV8P2BSDxH5BMgD7lTVdxoxVmOar/T0Iy+mrsKO7GyOz8o6PEIVcnPhm28On2MrLT38uqDAHc2tWeP64KpJcEdiaWkuefl8h8+5+c+3nXCCPQPN1ImoRuYgRkQuACao6pXe8GXAaFW9torylwDjVfVyEUkAklU1V0RGAAuAAUFHZIjIdGA6QEZGxoj58+fXOd6CggKSk6P3mIBose1uWeq93aokfPstbbZvJ37fPuLz8ojPyyMuL4/4AweIz8sjadcuEr/55vAsMTEUHnssJWlpIY/ENCaGsqQkyhIT3d/Wrd3fpCRK27RxfXIyZcnJlHr9odRUtBbXwdnnXbVx48atVNU6nHhtfJE8wtoJdA0Y7uKNq8p84C8AqloMFHuvV4rIZqA3sCJwBlWdA8wByMzM1KzAX461lJ2dTX3mb65su1uWiG33wYOuynH9emT9elqvX0/rPXtCl/UfyX37rfvr76sTG+uqJAMvA/Bf+1ZefkTLzM0bNnD8Mce4uAL7oiKXRGNiKvcilZOr/7UItG/v7oRyzDEuBv/rdu1qd72dKhQXV97m/HzXujQ52R21pqW5Ktfg5Fxe7sofOOB6YtAQSAAACsRJREFUEVdNG6S57+eRTFjLgV4i0gOXqC4CLgksICK9VPULb/Bs4AtvfAdgr6qWiUhPoBewJWKRG2Pqp3VrdwlAVZcB1KS83CUUf6ORwL/79rkGKP5WlCtXwoIF7su/ChUP30hKcrH5+4QElzhU3ToDe7/AWqnycncD5gMHQq9IxDV4adXK9fHxLtn4q1lLSw+/Lik58lKGqpbZrp1LlKWlbt15eZXjGj0aPvig5mU1MxFLWKpaKiLXAotxzdqfVNW1IjIbWKGqC4FrReR04BCwD7jcm30sMFtEDgHlwAxV3Rup2I0xURYT444ykpNdQ5OaqLrGJ4WFLkHExFS6y8jSZf/f3r0HW1WWcRz//kJUvOQNNRWFNKfUDCI1HG9oU2BSNHYZTUezGmtGJ5wwRfOCpnnJypqyybzAOJg3vKJdSBi1YkREDRRLJE2JQAtEBVHk6Y/33eNieQ5y2eess/b+fWbW7L3e/e61nneddfaz12W/7zQOHTYslTfDsmWwYMHq09KlKQm99VZ6bExvv53uvGxMjTsxGz8iL099+qSjp8WLU3IsTr17pyOu8rTzzs1pVw/Trb/Dioj7gPtKZecVno/q5H0TgYldG52ZtQwp9RbSiVV9+jQvWUE6Omv0M2ldpol/MTMzs67jhGVmZrXghGVmZrXghGVmZrXghGVmZrXghGVmZrXghGVmZrXghGVmZrXQbZ3fdjdJLwHPb8Ai+gKddHbW0tzu9uJ2t5e1aXf/iOj8V9cVatmEtaEkzeipPRZ3Jbe7vbjd7aXu7fYpQTMzqwUnLDMzqwUnrM5dXXUAFXG724vb3V5q3W5fwzIzs1rwEZaZmdWCE5aZmdWCE1aJpOGS/i5prqQxVcfTlSRdJ2mRpNmFsm0lTZb0TH7cpsoYm03SrpKmSnpK0pOSRuXyVm/3ppKmS3oit/uCXP5BSQ/n/f1mSRtXHWtXkNRL0mOSJuX5dmn3c5JmSXpc0oxcVtt93QmrQFIv4JfAkcDewLGS9q42qi41DhheKhsD3B8RewL35/lWshIYHRF7A0OAU/LfuNXbvQI4IiIGAoOA4ZKGAJcBP42IDwGLgW9UGGNXGgXMKcy3S7sBDo+IQYXfX9V2X3fCWt0BwNyImBcRbwI3ASMrjqnLRMSDwP9KxSOB8fn5eOAL3RpUF4uIBRExMz9/lfQhtgut3+6IiNfybO88BXAEcFsub7l2A0jqBxwFXJPnRRu0ew1qu687Ya1uF+CFwvyLuayd7BgRC/Lz/wA7VhlMV5I0APg48DBt0O58WuxxYBEwGXgWWBIRK3OVVt3frwTOAFbl+e1oj3ZD+lLyR0mPSjo5l9V2X9+o6gCs54qIkNSSv3uQtAUwETgtIpamL91Jq7Y7It4GBknaGrgD+EjFIXU5SSOARRHxqKShVcdTgYMjYr6kHYDJkp4uvli3fd1HWKubD+xamO+Xy9rJQkk7AeTHRRXH03SSepOS1YSIuD0Xt3y7GyJiCTAVOBDYWlLji2sr7u8HAZ+X9BzpFP8RwM9o/XYDEBHz8+Mi0peUA6jxvu6EtbpHgD3zHUQbA8cAd1ccU3e7GzgxPz8RuKvCWJouX7+4FpgTET8pvNTq7d4+H1khqQ/wadL1u6nAl3K1lmt3RJwVEf0iYgDp/3lKRBxHi7cbQNLmkrZsPAc+A8ymxvu6e7ookfRZ0jnvXsB1EXFxxSF1GUm/BYaShhxYCJwP3AncAuxGGp7lKxFRvjGjtiQdDDwEzOKdaxpnk65jtXK7P0a6wN6L9EX1loi4UNLupCOPbYHHgOMjYkV1kXadfErw9IgY0Q7tzm28I89uBNwYERdL2o6a7utOWGZmVgs+JWhmZrXghGVmZrXghGVmZrXghGVmZrXghGVmZrXghGVtS9K4Ru/dPYWkkbkX7ZWSxlUdT2ckDZUUkvpWHYu1Dycsq0ROFiHp3FJ5u38QXkvqhaM/qYdxM8ucsKxKbwDfk7R91YE0U+76aX3etzWpY9Y/RMT8iHiluZGZ1ZsTllVpKvAccG5nFTo64pI0IJftV6pzZO6VermkhyT1k3RYHrTwNUmT8q/8y+s4R9LCXOf63HVR4zVJOkPSs3m5syQd30Esx0qaImk58K1O2rKNpPGSFudl/UnSPo02kMZlApiSlzm0k+VsLOkySS9KWibpEUnDOthmI5QG7nsjb5dPlJZzdG7PCkkvSPq+Cr0A5/X8UNLzuc48Sd8phTNQaSDEZZJmSBpceP9Wkm5QGiT0jfz+0zpqk9nacMKyKq0iDR73bUl7NGF5FwCnAZ8EtgFuBs4DTiZ1QbUPMLb0nsOAgcCngC+S+lu7rPD6RaTB/U4hDep5CfBrSUeVlnMJcFWuc2cn8Y3LsY0kdUK6DPh9TpB/zfGR49gpl3Xk+hz3V4GPkrpcukfSwFK9K4Azgf2AecAkSZsB5OR1K3A7sC/p73AWcGrh/eOBE4DvAnvl7bCkg3aPAQYD/wUmFJLeRXnZI4APA1+nRTuZtW4SEZ48dftE+vCelJ9PBW7Kz4eSxvDp29F8LhuQy/Yr1RlWqHNqLhtcKBsLzC7FsATYolB2PGl03s3ztBw4pBT7lcB9pVhGv0d798z1Di2UbQW8Anwzz/fNdYauYTl7kBL9bqXyO4GrStvjuMLrW+S2NtY1gdQRbHEZY4EXS/EO7ySOjrb5QbmsX56/m9QfZ+X7m6fWmDwelvUEZwLTJP1oA5fzt8LzhflxVqlsh/J74p2ReAGmARuTEsMmwKako6Bip5u9Sacyi2a8R2x7kRLNtEZBRLwiaRbpqGxtDQYEPFU4e0eOdUqpbnFdr5XWtRdwb6n+n4HzJb2fNLDlKtKXiTUpbvN/58cdSIMi/gq4LR/NTQbuiYgH3mN5Zp1ywrLKRcR0SROBy4EflF5u9Khe/HTu7KaGt4qLzcsul63LafBG3c8B/1rDugBeX4fllq1LD9Tvy/X37yCG5RsQw/rG865tTt5uEfE7Sf2BI0mnXO+VdGtEnNScMK3d+BqW9RRnA4cAw0vlL+XHnQplg5q43n2VxgpqGAK8SRo+/inS6cH+ETG3ND2/juuZQ/p/O7BRkI9k9s3rWVuPkZL3BzqIqXx9aEhhXZuTrnfNKcRzUKn+waRTgq8Cj+d4D1+H2N4lIl6OiBsi4muka2AnStpkQ5Zp7ctHWNYjRMRcSVfz7t8ezQVeAMZKGkO6ZnROE1e9EXCdpAuBnYFLgd9ExOsAkq4Arsg3EjxIuhY0BFgVEVev7Uoi4hlJd5Fu2DiZdD3pYmApcOM6LOcfkiYA4ySNBmaSxnQaCsyLd0ZQBjhH0kukU3XnkRJxY10/Bh6RNDaX7Q+MJn1xaKznFuAaSaPyevoBAyLihrWJNW/TmcCTpO18dI6xpcadsu7jIyzrSS4EVhYL8im9Y4DdgSdIdwKe3cR1PkD6QJ1KGuxuCnBG4fVzSTcjnJ7rTSbdxffP9VjXScB00s0I04HNSDc1rOupvJNIdwpeDjwNTAIOJQ3GVzSGlJhmkm6iGNFIxBExE/hybstsUqK+FPhF4f0nkJLZz/N6xpFuFFlbK0hJ+QngL8CWpNOrZuvFAziatZj8+62pwPYR8XLF4Zg1jY+wzMysFpywzMysFnxK0MzMasFHWGZmVgtOWGZmVgtOWGZmVgtOWGZmVgtOWGZmVgv/B6vAFB8CkQSpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woXJqKNsfLVa"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWj7qtnje7Sg",
        "outputId": "5347ad7c-7680-4d7c-99a8-793703a1f7b3"
      },
      "source": [
        "NN_evaluate(X_train, y_train, X_test, y_test, learned_parameters, ACTIVATION)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy = 88 %\n",
            "Test accuracy = 86 %\n",
            "Classification report for the test set:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81      1000\n",
            "           1       0.99      0.95      0.97      1000\n",
            "           2       0.80      0.72      0.76      1000\n",
            "           3       0.87      0.88      0.87      1000\n",
            "           4       0.76      0.79      0.77      1000\n",
            "           5       0.96      0.92      0.94      1000\n",
            "           6       0.62      0.72      0.67      1000\n",
            "           7       0.91      0.95      0.93      1000\n",
            "           8       0.94      0.96      0.95      1000\n",
            "           9       0.94      0.95      0.94      1000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4xvwwJrMqxF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}